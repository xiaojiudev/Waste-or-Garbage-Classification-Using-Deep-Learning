"C:\Program Files\Python310\python.exe" D:\Study\CNTT\A.MHUD\CNN_Practice\MODEL_RESNET50.py 
GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
TensorFlow is using GPU: True
2025-03-09 14:16:57.620129: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-03-09 14:16:58.149333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8192 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6
1 Physical GPU, 1 Logical GPUs
Found 10321 images belonging to 9 classes.
Found 2574 images belonging to 9 classes.
Found 5521 images belonging to 9 classes.
Training class distribution: Counter({2: 2820, 3: 1124, 7: 1112, 8: 1108, 5: 1020, 6: 868, 1: 779, 4: 762, 0: 728})
Validation class distribution: Counter({2: 704, 3: 281, 7: 277, 8: 276, 5: 254, 6: 216, 1: 194, 4: 190, 0: 182})
Testing class distribution: Counter({2: 1509, 3: 602, 7: 594, 8: 592, 5: 545, 6: 464, 1: 417, 4: 408, 0: 390})
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               
                                )]                                                                
                                                                                                  
 conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                
                                                                                                  
 conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              
                                )                                                                 
                                                                                                  
 conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             
                                )                                                                 
                                                                                                  
 conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               
                                )                                                                 
                                                                                                  
 pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             
                                )                                                                 
                                                                                                  
 pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              
                                                                                                  
 conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             
                                                                                                  
 conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    
                                                                                                  
 conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             
                                                                                                  
 conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    
                                                                                                  
 conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      
                                                                  'conv2_block1_3_bn[0][0]']      
                                                                                                  
 conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       
                                                                                                  
 conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       
                                                                                                  
 conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    
                                                                                                  
 conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    
                                                                                                  
 conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       
                                                                  'conv2_block2_3_bn[0][0]']      
                                                                                                  
 conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       
                                                                                                  
 conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       
                                                                                                  
 conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    
                                                                                                  
 conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    
                                                                                                  
 conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       
                                                                  'conv2_block3_3_bn[0][0]']      
                                                                                                  
 conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       
                                                                                                  
 conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       
                                                                                                  
 conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    
                                                                                                  
 conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       
                                                                                                  
 conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    
                                                                                                  
 conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      
                                                                  'conv3_block1_3_bn[0][0]']      
                                                                                                  
 conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       
                                                                                                  
 conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       
                                                                                                  
 conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    
                                                                                                  
 conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    
                                                                                                  
 conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       
                                                                  'conv3_block2_3_bn[0][0]']      
                                                                                                  
 conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       
                                                                                                  
 conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       
                                                                                                  
 conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    
                                                                                                  
 conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    
                                                                                                  
 conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       
                                                                  'conv3_block3_3_bn[0][0]']      
                                                                                                  
 conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       
                                                                                                  
 conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       
                                                                                                  
 conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    
                                                                                                  
 conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    
                                                                                                  
 conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       
                                                                  'conv3_block4_3_bn[0][0]']      
                                                                                                  
 conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       
                                                                                                  
 conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       
                                                                                                  
 conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    
                                                                                                  
 conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       
                                )                                                                 
                                                                                                  
 conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    
                                )                                                                 
                                                                                                  
 conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    
 ization)                       )                                                                 
                                                                                                  
 conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    
 ization)                       )                                                                 
                                                                                                  
 conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      
                                )                                 'conv4_block1_3_bn[0][0]']      
                                                                                                  
 conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       
                                )                                                                 
                                                                                                  
 conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       
                                                                                                  
 conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    
                                                                                                  
 conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    
                                )                                                                 
                                                                                                  
 conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    
 ization)                       )                                                                 
                                                                                                  
 conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       
                                )                                 'conv4_block2_3_bn[0][0]']      
                                                                                                  
 conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       
                                )                                                                 
                                                                                                  
 conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       
                                                                                                  
 conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    
                                                                                                  
 conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    
                                )                                                                 
                                                                                                  
 conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    
 ization)                       )                                                                 
                                                                                                  
 conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       
                                )                                 'conv4_block3_3_bn[0][0]']      
                                                                                                  
 conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       
                                )                                                                 
                                                                                                  
 conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       
                                                                                                  
 conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    
                                                                                                  
 conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    
                                )                                                                 
                                                                                                  
 conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    
 ization)                       )                                                                 
                                                                                                  
 conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       
                                )                                 'conv4_block4_3_bn[0][0]']      
                                                                                                  
 conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       
                                )                                                                 
                                                                                                  
 conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       
                                                                                                  
 conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    
                                                                                                  
 conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    
                                )                                                                 
                                                                                                  
 conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    
 ization)                       )                                                                 
                                                                                                  
 conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       
                                )                                 'conv4_block5_3_bn[0][0]']      
                                                                                                  
 conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       
                                )                                                                 
                                                                                                  
 conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       
                                                                                                  
 conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    
                                                                                                  
 conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    
                                )                                                                 
                                                                                                  
 conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    
 ization)                       )                                                                 
                                                                                                  
 conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       
                                )                                 'conv4_block6_3_bn[0][0]']      
                                                                                                  
 conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       
                                )                                                                 
                                                                                                  
 conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       
                                                                                                  
 conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    
                                                                                                  
 conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       
                                                                                                  
 conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    
                                                                                                  
 conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      
                                                                  'conv5_block1_3_bn[0][0]']      
                                                                                                  
 conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       
                                                                                                  
 conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       
                                                                                                  
 conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    
                                                                                                  
 conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    
                                                                                                  
 conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       
                                                                  'conv5_block2_3_bn[0][0]']      
                                                                                                  
 conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       
                                                                                                  
 conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       
                                                                                                  
 conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    
                                                                                                  
 conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      
 n)                                                                                               
                                                                                                  
 conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    
                                                                                                  
 conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    
 ization)                                                                                         
                                                                                                  
 conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       
                                                                  'conv5_block3_3_bn[0][0]']      
                                                                                                  
 conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       
                                                                                                  
 conv2d (Conv2D)                (None, 7, 7, 128)    2359424     ['conv5_block3_out[0][0]']       
                                                                                                  
 max_pooling2d (MaxPooling2D)   (None, 3, 3, 128)    0           ['conv2d[0][0]']                 
                                                                                                  
 batch_normalization (BatchNorm  (None, 3, 3, 128)   512         ['max_pooling2d[0][0]']          
 alization)                                                                                       
                                                                                                  
 conv2d_1 (Conv2D)              (None, 3, 3, 128)    147584      ['batch_normalization[0][0]']    
                                                                                                  
 max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 128)   0           ['conv2d_1[0][0]']               
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 1, 1, 128)   512         ['max_pooling2d_1[0][0]']        
 rmalization)                                                                                     
                                                                                                  
 flatten (Flatten)              (None, 128)          0           ['batch_normalization_1[0][0]']  
                                                                                                  
 dense (Dense)                  (None, 512)          66048       ['flatten[0][0]']                
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 512)         2048        ['dense[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dropout (Dropout)              (None, 512)          0           ['batch_normalization_2[0][0]']  
                                                                                                  
 dense_1 (Dense)                (None, 256)          131328      ['dropout[0][0]']                
                                                                                                  
 batch_normalization_3 (BatchNo  (None, 256)         1024        ['dense_1[0][0]']                
 rmalization)                                                                                     
                                                                                                  
 dropout_1 (Dropout)            (None, 256)          0           ['batch_normalization_3[0][0]']  
                                                                                                  
 dense_2 (Dense)                (None, 128)          32896       ['dropout_1[0][0]']              
                                                                                                  
 batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_2[0][0]']                
 rmalization)                                                                                     
                                                                                                  
 dropout_2 (Dropout)            (None, 128)          0           ['batch_normalization_4[0][0]']  
                                                                                                  
 dense_3 (Dense)                (None, 9)            1161        ['dropout_2[0][0]']              
                                                                                                  
==================================================================================================
Total params: 26,330,761
Trainable params: 26,275,337
Non-trainable params: 55,424
__________________________________________________________________________________________________
Epoch 1/100
2025-03-09 14:17:11.630146: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8907
2025-03-09 14:17:12.198734: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
132/323 [===========>..................] - ETA: 1:15 - loss: 3.2784 - accuracy: 0.1851C:\Program Files\Python310\lib\site-packages\PIL\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
323/323 [==============================] - ETA: 0s - loss: 3.0263 - accuracy: 0.2127
Epoch 1: val_loss improved from inf to 3.42930, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 164s 473ms/step - loss: 3.0263 - accuracy: 0.2127 - val_loss: 3.4293 - val_accuracy: 0.0862 - lr: 0.0010
Epoch 2/100
323/323 [==============================] - ETA: 0s - loss: 2.5684 - accuracy: 0.3000
Epoch 2: val_loss improved from 3.42930 to 2.93615, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 150s 463ms/step - loss: 2.5684 - accuracy: 0.3000 - val_loss: 2.9361 - val_accuracy: 0.1465 - lr: 0.0010
Epoch 3/100
323/323 [==============================] - ETA: 0s - loss: 2.2740 - accuracy: 0.4152
Epoch 3: val_loss improved from 2.93615 to 2.27777, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 151s 467ms/step - loss: 2.2740 - accuracy: 0.4152 - val_loss: 2.2778 - val_accuracy: 0.3854 - lr: 0.0010
Epoch 4/100
323/323 [==============================] - ETA: 0s - loss: 2.0314 - accuracy: 0.4899
Epoch 4: val_loss improved from 2.27777 to 1.93162, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 152s 469ms/step - loss: 2.0314 - accuracy: 0.4899 - val_loss: 1.9316 - val_accuracy: 0.5051 - lr: 0.0010
Epoch 5/100
323/323 [==============================] - ETA: 0s - loss: 1.7563 - accuracy: 0.5734
Epoch 5: val_loss did not improve from 1.93162
323/323 [==============================] - 151s 467ms/step - loss: 1.7563 - accuracy: 0.5734 - val_loss: 2.0096 - val_accuracy: 0.4518 - lr: 0.0010
Epoch 6/100
323/323 [==============================] - ETA: 0s - loss: 1.5483 - accuracy: 0.6213
Epoch 6: val_loss did not improve from 1.93162
323/323 [==============================] - 151s 468ms/step - loss: 1.5483 - accuracy: 0.6213 - val_loss: 2.1004 - val_accuracy: 0.4448 - lr: 0.0010
Epoch 7/100
323/323 [==============================] - ETA: 0s - loss: 1.3671 - accuracy: 0.6636
Epoch 7: val_loss improved from 1.93162 to 1.83202, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 152s 469ms/step - loss: 1.3671 - accuracy: 0.6636 - val_loss: 1.8320 - val_accuracy: 0.5221 - lr: 0.0010
Epoch 8/100
323/323 [==============================] - ETA: 0s - loss: 1.2633 - accuracy: 0.6884
Epoch 8: val_loss did not improve from 1.83202
323/323 [==============================] - 152s 468ms/step - loss: 1.2633 - accuracy: 0.6884 - val_loss: 4.7419 - val_accuracy: 0.2133 - lr: 0.0010
Epoch 9/100
323/323 [==============================] - ETA: 0s - loss: 1.1234 - accuracy: 0.7187
Epoch 9: val_loss improved from 1.83202 to 1.73446, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 153s 471ms/step - loss: 1.1234 - accuracy: 0.7187 - val_loss: 1.7345 - val_accuracy: 0.5365 - lr: 0.0010
Epoch 10/100
323/323 [==============================] - ETA: 0s - loss: 1.0421 - accuracy: 0.7383
Epoch 10: val_loss did not improve from 1.73446
323/323 [==============================] - 151s 466ms/step - loss: 1.0421 - accuracy: 0.7383 - val_loss: 1.7882 - val_accuracy: 0.5198 - lr: 0.0010
Epoch 11/100
323/323 [==============================] - ETA: 0s - loss: 0.9504 - accuracy: 0.7607
Epoch 11: val_loss improved from 1.73446 to 1.17806, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 152s 468ms/step - loss: 0.9504 - accuracy: 0.7607 - val_loss: 1.1781 - val_accuracy: 0.6605 - lr: 0.0010
Epoch 12/100
323/323 [==============================] - ETA: 0s - loss: 0.9291 - accuracy: 0.7636
Epoch 12: val_loss did not improve from 1.17806
323/323 [==============================] - 151s 465ms/step - loss: 0.9291 - accuracy: 0.7636 - val_loss: 2.8009 - val_accuracy: 0.2844 - lr: 0.0010
Epoch 13/100
323/323 [==============================] - ETA: 0s - loss: 0.8704 - accuracy: 0.7774
Epoch 13: val_loss did not improve from 1.17806
323/323 [==============================] - 151s 466ms/step - loss: 0.8704 - accuracy: 0.7774 - val_loss: 1.4456 - val_accuracy: 0.5804 - lr: 0.0010
Epoch 14/100
323/323 [==============================] - ETA: 0s - loss: 0.8332 - accuracy: 0.7833
Epoch 14: val_loss did not improve from 1.17806

Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
323/323 [==============================] - 151s 466ms/step - loss: 0.8332 - accuracy: 0.7833 - val_loss: 1.1943 - val_accuracy: 0.6414 - lr: 0.0010
Epoch 15/100
323/323 [==============================] - ETA: 0s - loss: 0.6598 - accuracy: 0.8269
Epoch 15: val_loss improved from 1.17806 to 0.57167, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 152s 470ms/step - loss: 0.6598 - accuracy: 0.8269 - val_loss: 0.5717 - val_accuracy: 0.8516 - lr: 1.0000e-04
Epoch 16/100
323/323 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.8617
Epoch 16: val_loss did not improve from 0.57167
323/323 [==============================] - 151s 467ms/step - loss: 0.5664 - accuracy: 0.8617 - val_loss: 0.5835 - val_accuracy: 0.8454 - lr: 1.0000e-04
Epoch 17/100
323/323 [==============================] - ETA: 0s - loss: 0.5327 - accuracy: 0.8711
Epoch 17: val_loss improved from 0.57167 to 0.55636, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 152s 470ms/step - loss: 0.5327 - accuracy: 0.8711 - val_loss: 0.5564 - val_accuracy: 0.8559 - lr: 1.0000e-04
Epoch 18/100
323/323 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.8825
Epoch 18: val_loss improved from 0.55636 to 0.52371, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 152s 470ms/step - loss: 0.4958 - accuracy: 0.8825 - val_loss: 0.5237 - val_accuracy: 0.8570 - lr: 1.0000e-04
Epoch 19/100
323/323 [==============================] - ETA: 0s - loss: 0.4862 - accuracy: 0.8846
Epoch 19: val_loss did not improve from 0.52371
323/323 [==============================] - 151s 466ms/step - loss: 0.4862 - accuracy: 0.8846 - val_loss: 0.8615 - val_accuracy: 0.7525 - lr: 1.0000e-04
Epoch 20/100
323/323 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.8934
Epoch 20: val_loss improved from 0.52371 to 0.51197, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 152s 470ms/step - loss: 0.4546 - accuracy: 0.8934 - val_loss: 0.5120 - val_accuracy: 0.8621 - lr: 1.0000e-04
Epoch 21/100
323/323 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 0.9000
Epoch 21: val_loss improved from 0.51197 to 0.43795, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 152s 469ms/step - loss: 0.4159 - accuracy: 0.9000 - val_loss: 0.4380 - val_accuracy: 0.8869 - lr: 1.0000e-04
Epoch 22/100
323/323 [==============================] - ETA: 0s - loss: 0.4192 - accuracy: 0.8967
Epoch 22: val_loss did not improve from 0.43795
323/323 [==============================] - 152s 469ms/step - loss: 0.4192 - accuracy: 0.8967 - val_loss: 0.4999 - val_accuracy: 0.8679 - lr: 1.0000e-04
Epoch 23/100
323/323 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.9013
Epoch 23: val_loss improved from 0.43795 to 0.43055, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 152s 469ms/step - loss: 0.4033 - accuracy: 0.9013 - val_loss: 0.4305 - val_accuracy: 0.8854 - lr: 1.0000e-04
Epoch 24/100
323/323 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.9104
Epoch 24: val_loss did not improve from 0.43055
323/323 [==============================] - 151s 465ms/step - loss: 0.3753 - accuracy: 0.9104 - val_loss: 0.4359 - val_accuracy: 0.8831 - lr: 1.0000e-04
Epoch 25/100
323/323 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.9145
Epoch 25: val_loss improved from 0.43055 to 0.41878, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 152s 471ms/step - loss: 0.3596 - accuracy: 0.9145 - val_loss: 0.4188 - val_accuracy: 0.8912 - lr: 1.0000e-04
Epoch 26/100
323/323 [==============================] - ETA: 0s - loss: 0.3565 - accuracy: 0.9123
Epoch 26: val_loss did not improve from 0.41878
323/323 [==============================] - 152s 469ms/step - loss: 0.3565 - accuracy: 0.9123 - val_loss: 0.4264 - val_accuracy: 0.8858 - lr: 1.0000e-04
Epoch 27/100
323/323 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.9182
Epoch 27: val_loss did not improve from 0.41878
323/323 [==============================] - 152s 469ms/step - loss: 0.3305 - accuracy: 0.9182 - val_loss: 0.4549 - val_accuracy: 0.8745 - lr: 1.0000e-04
Epoch 28/100
323/323 [==============================] - ETA: 0s - loss: 0.3284 - accuracy: 0.9183
Epoch 28: val_loss did not improve from 0.41878

Epoch 28: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
323/323 [==============================] - 151s 467ms/step - loss: 0.3284 - accuracy: 0.9183 - val_loss: 0.4998 - val_accuracy: 0.8671 - lr: 1.0000e-04
Epoch 29/100
323/323 [==============================] - ETA: 0s - loss: 0.3004 - accuracy: 0.9256
Epoch 29: val_loss improved from 0.41878 to 0.38381, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 152s 468ms/step - loss: 0.3004 - accuracy: 0.9256 - val_loss: 0.3838 - val_accuracy: 0.9033 - lr: 1.0000e-05
Epoch 30/100
323/323 [==============================] - ETA: 0s - loss: 0.2768 - accuracy: 0.9338
Epoch 30: val_loss improved from 0.38381 to 0.35275, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 151s 467ms/step - loss: 0.2768 - accuracy: 0.9338 - val_loss: 0.3527 - val_accuracy: 0.9149 - lr: 1.0000e-05
Epoch 31/100
323/323 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.9393
Epoch 31: val_loss did not improve from 0.35275
323/323 [==============================] - 151s 467ms/step - loss: 0.2623 - accuracy: 0.9393 - val_loss: 0.3746 - val_accuracy: 0.9044 - lr: 1.0000e-05
Epoch 32/100
323/323 [==============================] - ETA: 0s - loss: 0.2732 - accuracy: 0.9358
Epoch 32: val_loss did not improve from 0.35275
323/323 [==============================] - 151s 467ms/step - loss: 0.2732 - accuracy: 0.9358 - val_loss: 0.3706 - val_accuracy: 0.9048 - lr: 1.0000e-05
Epoch 33/100
323/323 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.9385
Epoch 33: val_loss did not improve from 0.35275

Epoch 33: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
323/323 [==============================] - 152s 469ms/step - loss: 0.2644 - accuracy: 0.9385 - val_loss: 0.3553 - val_accuracy: 0.9099 - lr: 1.0000e-05
Epoch 34/100
323/323 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.9405
Epoch 34: val_loss did not improve from 0.35275
323/323 [==============================] - 152s 468ms/step - loss: 0.2603 - accuracy: 0.9405 - val_loss: 0.3655 - val_accuracy: 0.9075 - lr: 1.0000e-06
Epoch 35/100
323/323 [==============================] - ETA: 0s - loss: 0.2472 - accuracy: 0.9435
Epoch 35: val_loss did not improve from 0.35275
323/323 [==============================] - 152s 469ms/step - loss: 0.2472 - accuracy: 0.9435 - val_loss: 0.3637 - val_accuracy: 0.9083 - lr: 1.0000e-06
Epoch 36/100
323/323 [==============================] - ETA: 0s - loss: 0.2614 - accuracy: 0.9391
Epoch 36: val_loss did not improve from 0.35275

Epoch 36: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.
323/323 [==============================] - 151s 468ms/step - loss: 0.2614 - accuracy: 0.9391 - val_loss: 0.3736 - val_accuracy: 0.9068 - lr: 1.0000e-06
Epoch 37/100
323/323 [==============================] - ETA: 0s - loss: 0.2524 - accuracy: 0.9412
Epoch 37: val_loss improved from 0.35275 to 0.34765, saving model to resnet50_saved_2025-03-09_14-16-58.keras
323/323 [==============================] - 153s 471ms/step - loss: 0.2524 - accuracy: 0.9412 - val_loss: 0.3476 - val_accuracy: 0.9138 - lr: 1.0000e-07
Epoch 38/100
323/323 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.9406
Epoch 38: val_loss did not improve from 0.34765
323/323 [==============================] - 151s 467ms/step - loss: 0.2582 - accuracy: 0.9406 - val_loss: 0.3577 - val_accuracy: 0.9134 - lr: 1.0000e-07
Epoch 39/100
323/323 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.9400
Epoch 39: val_loss did not improve from 0.34765
323/323 [==============================] - 151s 467ms/step - loss: 0.2577 - accuracy: 0.9400 - val_loss: 0.3557 - val_accuracy: 0.9099 - lr: 1.0000e-07
Epoch 40/100
323/323 [==============================] - ETA: 0s - loss: 0.2605 - accuracy: 0.9416
Epoch 40: val_loss did not improve from 0.34765

Epoch 40: ReduceLROnPlateau reducing learning rate to 1e-07.
323/323 [==============================] - 151s 467ms/step - loss: 0.2605 - accuracy: 0.9416 - val_loss: 0.3732 - val_accuracy: 0.9087 - lr: 1.0000e-07
Epoch 41/100
323/323 [==============================] - ETA: 0s - loss: 0.2653 - accuracy: 0.9378
Epoch 41: val_loss did not improve from 0.34765
323/323 [==============================] - 151s 466ms/step - loss: 0.2653 - accuracy: 0.9378 - val_loss: 0.3698 - val_accuracy: 0.9052 - lr: 1.0000e-07
Epoch 42/100
323/323 [==============================] - ETA: 0s - loss: 0.2587 - accuracy: 0.9402
Epoch 42: val_loss did not improve from 0.34765
323/323 [==============================] - 151s 467ms/step - loss: 0.2587 - accuracy: 0.9402 - val_loss: 0.3747 - val_accuracy: 0.9044 - lr: 1.0000e-07
Epoch 43/100
323/323 [==============================] - ETA: 0s - loss: 0.2559 - accuracy: 0.9413
Epoch 43: val_loss did not improve from 0.34765
323/323 [==============================] - 152s 468ms/step - loss: 0.2559 - accuracy: 0.9413 - val_loss: 0.3604 - val_accuracy: 0.9110 - lr: 1.0000e-07
Epoch 44/100
323/323 [==============================] - ETA: 0s - loss: 0.2551 - accuracy: 0.9423
Epoch 44: val_loss did not improve from 0.34765
323/323 [==============================] - 152s 470ms/step - loss: 0.2551 - accuracy: 0.9423 - val_loss: 0.3575 - val_accuracy: 0.9083 - lr: 1.0000e-07
Epoch 45/100
323/323 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.9411
Epoch 45: val_loss did not improve from 0.34765
323/323 [==============================] - 152s 468ms/step - loss: 0.2503 - accuracy: 0.9411 - val_loss: 0.3599 - val_accuracy: 0.9075 - lr: 1.0000e-07
Epoch 46/100
323/323 [==============================] - ETA: 0s - loss: 0.2557 - accuracy: 0.9424
Epoch 46: val_loss did not improve from 0.34765
323/323 [==============================] - 153s 472ms/step - loss: 0.2557 - accuracy: 0.9424 - val_loss: 0.3675 - val_accuracy: 0.9068 - lr: 1.0000e-07
Epoch 47/100
323/323 [==============================] - ETA: 0s - loss: 0.2629 - accuracy: 0.9407
Epoch 47: val_loss did not improve from 0.34765
323/323 [==============================] - 152s 468ms/step - loss: 0.2629 - accuracy: 0.9407 - val_loss: 0.3735 - val_accuracy: 0.9021 - lr: 1.0000e-07
Test Accuracy: 0.9270
173/173 [==============================] - 20s 111ms/step
              precision    recall  f1-score   support

     battery       0.96      0.88      0.92       390
   cardboard       0.97      0.93      0.95       417
     clothes       0.99      0.98      0.98      1509
       glass       0.91      0.87      0.89       602
       metal       0.79      0.87      0.83       408
     organic       0.96      0.94      0.95       545
       paper       0.88      0.95      0.91       464
     plastic       0.88      0.89      0.88       594
       shoes       0.90      0.94      0.92       592

    accuracy                           0.93      5521
   macro avg       0.92      0.92      0.92      5521
weighted avg       0.93      0.93      0.93      5521

[[ 345    5    2    1   20    1    6    4    6]
 [   4  388    3    3    1    0   12    3    3]
 [   0    0 1473    0    5    1   20    2    8]
 [   1    0    0  524   25    7    0   36    9]
 [   6    0    2   12  354    2    5   15   12]
 [   0    1    2    5    3  510    6    3   15]
 [   0    3    4    0    7    0  443    5    2]
 [   2    1    2   22   23    3   10  526    5]
 [   2    1    4    6   10    6    3    5  555]]

Process finished with exit code 0

2025-04-04
"C:\Program Files\Python310\python.exe" D:\Study\CNTT\A.MHUD\CNN_Practice\MODEL_RESNET50.py
2025-04-05 00:47:35.154852: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
TensorFlow is using GPU: True
1 Physical GPU, 1 Logical GPUs
2025-04-05 00:47:36.094473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8192 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6
Found 11792 images belonging to 9 classes.
Found 2944 images belonging to 9 classes.
Found 3680 images belonging to 9 classes.
Training class distribution: Counter({2: 3222, 3: 1285, 7: 1270, 8: 1265, 5: 1165, 6: 992, 1: 890, 4: 871, 0: 832})
Validation class distribution: Counter({2: 805, 3: 321, 7: 317, 8: 316, 5: 291, 6: 247, 1: 222, 4: 217, 0: 208})
Testing class distribution: Counter({2: 1006, 3: 401, 7: 396, 8: 395, 5: 363, 6: 309, 1: 278, 4: 272, 0: 260})
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-123.68..148.061].
Total layers: 175, Fine-tuning last 35 layers
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 224, 224, 3  0           []
                                )]

 conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']

 conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']
                                )

 conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']
                                )

 conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']
                                )

 pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']
                                )

 pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']

 conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']

 conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']
 ization)

 conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']
 n)

 conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']

 conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']
 ization)

 conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']
 n)

 conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']

 conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']

 conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']
 ization)

 conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']
 ization)

 conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',
                                                                  'conv2_block1_3_bn[0][0]']

 conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']

 conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']

 conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']
 ization)

 conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']
 n)

 conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']

 conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']
 ization)

 conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']
 n)

 conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']

 conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']
 ization)

 conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',
                                                                  'conv2_block2_3_bn[0][0]']

 conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']

 conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']

 conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']
 ization)

 conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']
 n)

 conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']

 conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']
 ization)

 conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']
 n)

 conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']

 conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']
 ization)

 conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',
                                                                  'conv2_block3_3_bn[0][0]']

 conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']

 conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']

 conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']
 ization)

 conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']
 n)

 conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']

 conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']
 ization)

 conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']
 n)

 conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']

 conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']

 conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']
 ization)

 conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']
 ization)

 conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',
                                                                  'conv3_block1_3_bn[0][0]']

 conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']

 conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']

 conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']
 ization)

 conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']
 n)

 conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']

 conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']
 ization)

 conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']
 n)

 conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']

 conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']
 ization)

 conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',
                                                                  'conv3_block2_3_bn[0][0]']

 conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']

 conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']

 conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']
 ization)

 conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']
 n)

 conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']

 conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']
 ization)

 conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']
 n)

 conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']

 conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']
 ization)

 conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',
                                                                  'conv3_block3_3_bn[0][0]']

 conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']

 conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']

 conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']
 ization)

 conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']
 n)

 conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']

 conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']
 ization)

 conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']
 n)

 conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']

 conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']
 ization)

 conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',
                                                                  'conv3_block4_3_bn[0][0]']

 conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']

 conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']

 conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']
 ization)

 conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']
 n)

 conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']

 conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']
 ization)

 conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']
 n)

 conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']
                                )

 conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']
                                )

 conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']
 ization)                       )

 conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']
 ization)                       )

 conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',
                                )                                 'conv4_block1_3_bn[0][0]']

 conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']
                                )

 conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']

 conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']
 ization)

 conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']
 n)

 conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']

 conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']
 ization)

 conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']
 n)

 conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']
                                )

 conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']
 ization)                       )

 conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',
                                )                                 'conv4_block2_3_bn[0][0]']

 conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']
                                )

 conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']

 conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']
 ization)

 conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']
 n)

 conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']

 conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']
 ization)

 conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']
 n)

 conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']
                                )

 conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']
 ization)                       )

 conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',
                                )                                 'conv4_block3_3_bn[0][0]']

 conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']
                                )

 conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']

 conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']
 ization)

 conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']
 n)

 conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']

 conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']
 ization)

 conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']
 n)

 conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']
                                )

 conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']
 ization)                       )

 conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',
                                )                                 'conv4_block4_3_bn[0][0]']

 conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']
                                )

 conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']

 conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']
 ization)

 conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']
 n)

 conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']

 conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']
 ization)

 conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']
 n)

 conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']
                                )

 conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']
 ization)                       )

 conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',
                                )                                 'conv4_block5_3_bn[0][0]']

 conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']
                                )

 conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']

 conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']
 ization)

 conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']
 n)

 conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']

 conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']
 ization)

 conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']
 n)

 conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']
                                )

 conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']
 ization)                       )

 conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',
                                )                                 'conv4_block6_3_bn[0][0]']

 conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']
                                )

 conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']

 conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']
 ization)

 conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']
 n)

 conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']

 conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']
 ization)

 conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']
 n)

 conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']

 conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']

 conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']
 ization)

 conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']
 ization)

 conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',
                                                                  'conv5_block1_3_bn[0][0]']

 conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']

 conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']

 conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']
 ization)

 conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']
 n)

 conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']

 conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']
 ization)

 conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']
 n)

 conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']

 conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']
 ization)

 conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',
                                                                  'conv5_block2_3_bn[0][0]']

 conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']

 conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']

 conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']
 ization)

 conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']
 n)

 conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']

 conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']
 ization)

 conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']
 n)

 conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']

 conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']
 ization)

 conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',
                                                                  'conv5_block3_3_bn[0][0]']

 conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']

 conv2d (Conv2D)                (None, 7, 7, 128)    2359424     ['conv5_block3_out[0][0]']

 max_pooling2d (MaxPooling2D)   (None, 3, 3, 128)    0           ['conv2d[0][0]']

 batch_normalization (BatchNorm  (None, 3, 3, 128)   512         ['max_pooling2d[0][0]']
 alization)

 conv2d_1 (Conv2D)              (None, 3, 3, 128)    147584      ['batch_normalization[0][0]']

 max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 128)   0           ['conv2d_1[0][0]']

 batch_normalization_1 (BatchNo  (None, 1, 1, 128)   512         ['max_pooling2d_1[0][0]']
 rmalization)

 flatten (Flatten)              (None, 128)          0           ['batch_normalization_1[0][0]']

 dense (Dense)                  (None, 512)          66048       ['flatten[0][0]']

 batch_normalization_2 (BatchNo  (None, 512)         2048        ['dense[0][0]']
 rmalization)

 dropout (Dropout)              (None, 512)          0           ['batch_normalization_2[0][0]']

 dense_1 (Dense)                (None, 256)          131328      ['dropout[0][0]']

 batch_normalization_3 (BatchNo  (None, 256)         1024        ['dense_1[0][0]']
 rmalization)

 dropout_1 (Dropout)            (None, 256)          0           ['batch_normalization_3[0][0]']

 dense_2 (Dense)                (None, 128)          32896       ['dropout_1[0][0]']

 batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_2[0][0]']
 rmalization)

 dropout_2 (Dropout)            (None, 128)          0           ['batch_normalization_4[0][0]']

 dense_3 (Dense)                (None, 9)            1161        ['dropout_2[0][0]']

==================================================================================================
Total params: 26,330,761
Trainable params: 26,275,337
Non-trainable params: 55,424
__________________________________________________________________________________________________
Epoch 1/100
2025-04-05 00:47:47.865895: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8907
2025-04-05 00:47:50.745087: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
142/369 [==========>...................] - ETA: 1:18 - loss: 3.2027 - accuracy: 0.2102C:\Program Files\Python310\lib\site-packages\PIL\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
369/369 [==============================] - ETA: 0s - loss: 2.9284 - accuracy: 0.2650
Epoch 1: val_loss improved from inf to 5.39461, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 176s 440ms/step - loss: 2.9284 - accuracy: 0.2650 - val_loss: 5.3946 - val_accuracy: 0.2069 - lr: 0.0010
Epoch 2/100
369/369 [==============================] - ETA: 0s - loss: 2.3658 - accuracy: 0.4152
Epoch 2: val_loss improved from 5.39461 to 2.25787, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 160s 432ms/step - loss: 2.3658 - accuracy: 0.4152 - val_loss: 2.2579 - val_accuracy: 0.4657 - lr: 0.0010
Epoch 3/100
369/369 [==============================] - ETA: 0s - loss: 2.1183 - accuracy: 0.4818
Epoch 3: val_loss improved from 2.25787 to 2.08777, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 164s 443ms/step - loss: 2.1183 - accuracy: 0.4818 - val_loss: 2.0878 - val_accuracy: 0.4660 - lr: 0.0010
Epoch 4/100
369/369 [==============================] - ETA: 0s - loss: 1.9096 - accuracy: 0.5259
Epoch 4: val_loss did not improve from 2.08777
369/369 [==============================] - 164s 442ms/step - loss: 1.9096 - accuracy: 0.5259 - val_loss: 2.8534 - val_accuracy: 0.3736 - lr: 0.0010
Epoch 5/100
369/369 [==============================] - ETA: 0s - loss: 1.8009 - accuracy: 0.5294
Epoch 5: val_loss improved from 2.08777 to 1.92273, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 160s 434ms/step - loss: 1.8009 - accuracy: 0.5294 - val_loss: 1.9227 - val_accuracy: 0.4480 - lr: 0.0010
Epoch 6/100
369/369 [==============================] - ETA: 0s - loss: 1.7133 - accuracy: 0.5352
Epoch 6: val_loss improved from 1.92273 to 1.64841, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 159s 430ms/step - loss: 1.7133 - accuracy: 0.5352 - val_loss: 1.6484 - val_accuracy: 0.5408 - lr: 0.0010
Epoch 7/100
369/369 [==============================] - ETA: 0s - loss: 1.5703 - accuracy: 0.5636
Epoch 7: val_loss did not improve from 1.64841
369/369 [==============================] - 160s 431ms/step - loss: 1.5703 - accuracy: 0.5636 - val_loss: 1.9888 - val_accuracy: 0.4742 - lr: 0.0010
Epoch 8/100
369/369 [==============================] - ETA: 0s - loss: 1.5049 - accuracy: 0.5781
Epoch 8: val_loss improved from 1.64841 to 1.51822, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 160s 432ms/step - loss: 1.5049 - accuracy: 0.5781 - val_loss: 1.5182 - val_accuracy: 0.5489 - lr: 0.0010
Epoch 9/100
369/369 [==============================] - ETA: 0s - loss: 1.3977 - accuracy: 0.6007
Epoch 9: val_loss did not improve from 1.51822
369/369 [==============================] - 161s 433ms/step - loss: 1.3977 - accuracy: 0.6007 - val_loss: 3.5061 - val_accuracy: 0.4484 - lr: 0.0010
Epoch 10/100
369/369 [==============================] - ETA: 0s - loss: 1.3161 - accuracy: 0.6200
Epoch 10: val_loss improved from 1.51822 to 1.29528, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 160s 433ms/step - loss: 1.3161 - accuracy: 0.6200 - val_loss: 1.2953 - val_accuracy: 0.6005 - lr: 0.0010
Epoch 11/100
369/369 [==============================] - ETA: 0s - loss: 1.2642 - accuracy: 0.6409
Epoch 11: val_loss did not improve from 1.29528
369/369 [==============================] - 159s 429ms/step - loss: 1.2642 - accuracy: 0.6409 - val_loss: 1.3617 - val_accuracy: 0.5954 - lr: 0.0010
Epoch 12/100
369/369 [==============================] - ETA: 0s - loss: 1.2799 - accuracy: 0.6304
Epoch 12: val_loss did not improve from 1.29528
369/369 [==============================] - 159s 428ms/step - loss: 1.2799 - accuracy: 0.6304 - val_loss: 1.3317 - val_accuracy: 0.6005 - lr: 0.0010
Epoch 13/100
369/369 [==============================] - ETA: 0s - loss: 1.1857 - accuracy: 0.6638
Epoch 13: val_loss improved from 1.29528 to 1.07273, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 160s 431ms/step - loss: 1.1857 - accuracy: 0.6638 - val_loss: 1.0727 - val_accuracy: 0.6872 - lr: 0.0010
Epoch 14/100
369/369 [==============================] - ETA: 0s - loss: 1.1628 - accuracy: 0.6746
Epoch 14: val_loss did not improve from 1.07273
369/369 [==============================] - 158s 428ms/step - loss: 1.1628 - accuracy: 0.6746 - val_loss: 1.1348 - val_accuracy: 0.6556 - lr: 0.0010
Epoch 15/100
369/369 [==============================] - ETA: 0s - loss: 1.0692 - accuracy: 0.7054
Epoch 15: val_loss did not improve from 1.07273
369/369 [==============================] - 159s 429ms/step - loss: 1.0692 - accuracy: 0.7054 - val_loss: 1.6135 - val_accuracy: 0.5268 - lr: 0.0010
Epoch 16/100
369/369 [==============================] - ETA: 0s - loss: 1.0343 - accuracy: 0.7186
Epoch 16: val_loss did not improve from 1.07273

Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
369/369 [==============================] - 156s 423ms/step - loss: 1.0343 - accuracy: 0.7186 - val_loss: 1.4594 - val_accuracy: 0.5666 - lr: 0.0010
Epoch 17/100
369/369 [==============================] - ETA: 0s - loss: 0.8494 - accuracy: 0.7759
Epoch 17: val_loss improved from 1.07273 to 0.73180, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 156s 421ms/step - loss: 0.8494 - accuracy: 0.7759 - val_loss: 0.7318 - val_accuracy: 0.7870 - lr: 1.0000e-04
Epoch 18/100
369/369 [==============================] - ETA: 0s - loss: 0.7829 - accuracy: 0.7938
Epoch 18: val_loss did not improve from 0.73180
369/369 [==============================] - 158s 427ms/step - loss: 0.7829 - accuracy: 0.7938 - val_loss: 0.7353 - val_accuracy: 0.7931 - lr: 1.0000e-04
Epoch 19/100
369/369 [==============================] - ETA: 0s - loss: 0.7421 - accuracy: 0.8089
Epoch 19: val_loss improved from 0.73180 to 0.68045, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 159s 431ms/step - loss: 0.7421 - accuracy: 0.8089 - val_loss: 0.6804 - val_accuracy: 0.8013 - lr: 1.0000e-04
Epoch 20/100
369/369 [==============================] - ETA: 0s - loss: 0.7009 - accuracy: 0.8107
Epoch 20: val_loss improved from 0.68045 to 0.66892, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 159s 429ms/step - loss: 0.7009 - accuracy: 0.8107 - val_loss: 0.6689 - val_accuracy: 0.8057 - lr: 1.0000e-04
Epoch 21/100
369/369 [==============================] - ETA: 0s - loss: 0.6799 - accuracy: 0.8179
Epoch 21: val_loss improved from 0.66892 to 0.61404, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 159s 431ms/step - loss: 0.6799 - accuracy: 0.8179 - val_loss: 0.6140 - val_accuracy: 0.8285 - lr: 1.0000e-04
Epoch 22/100
369/369 [==============================] - ETA: 0s - loss: 0.6575 - accuracy: 0.8251
Epoch 22: val_loss did not improve from 0.61404
369/369 [==============================] - 159s 430ms/step - loss: 0.6575 - accuracy: 0.8251 - val_loss: 0.6601 - val_accuracy: 0.8077 - lr: 1.0000e-04
Epoch 23/100
369/369 [==============================] - ETA: 0s - loss: 0.6272 - accuracy: 0.8325
Epoch 23: val_loss improved from 0.61404 to 0.60896, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 159s 430ms/step - loss: 0.6272 - accuracy: 0.8325 - val_loss: 0.6090 - val_accuracy: 0.8257 - lr: 1.0000e-04
Epoch 24/100
369/369 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.8351
Epoch 24: val_loss did not improve from 0.60896
369/369 [==============================] - 159s 430ms/step - loss: 0.6130 - accuracy: 0.8351 - val_loss: 0.6158 - val_accuracy: 0.8237 - lr: 1.0000e-04
Epoch 25/100
369/369 [==============================] - ETA: 0s - loss: 0.6000 - accuracy: 0.8382
Epoch 25: val_loss improved from 0.60896 to 0.59648, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 159s 430ms/step - loss: 0.6000 - accuracy: 0.8382 - val_loss: 0.5965 - val_accuracy: 0.8220 - lr: 1.0000e-04
Epoch 26/100
369/369 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.8435
Epoch 26: val_loss improved from 0.59648 to 0.57813, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 160s 431ms/step - loss: 0.5667 - accuracy: 0.8435 - val_loss: 0.5781 - val_accuracy: 0.8342 - lr: 1.0000e-04
Epoch 27/100
369/369 [==============================] - ETA: 0s - loss: 0.5369 - accuracy: 0.8544
Epoch 27: val_loss improved from 0.57813 to 0.55993, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 160s 432ms/step - loss: 0.5369 - accuracy: 0.8544 - val_loss: 0.5599 - val_accuracy: 0.8390 - lr: 1.0000e-04
Epoch 28/100
369/369 [==============================] - ETA: 0s - loss: 0.5192 - accuracy: 0.8614
Epoch 28: val_loss did not improve from 0.55993
369/369 [==============================] - 158s 428ms/step - loss: 0.5192 - accuracy: 0.8614 - val_loss: 0.5894 - val_accuracy: 0.8278 - lr: 1.0000e-04
Epoch 29/100
369/369 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.8593
Epoch 29: val_loss improved from 0.55993 to 0.54753, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 159s 431ms/step - loss: 0.5171 - accuracy: 0.8593 - val_loss: 0.5475 - val_accuracy: 0.8438 - lr: 1.0000e-04
Epoch 30/100
369/369 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.8658
Epoch 30: val_loss improved from 0.54753 to 0.51016, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 160s 433ms/step - loss: 0.4970 - accuracy: 0.8658 - val_loss: 0.5102 - val_accuracy: 0.8556 - lr: 1.0000e-04
Epoch 31/100
369/369 [==============================] - ETA: 0s - loss: 0.4761 - accuracy: 0.8708
Epoch 31: val_loss did not improve from 0.51016
369/369 [==============================] - 159s 429ms/step - loss: 0.4761 - accuracy: 0.8708 - val_loss: 0.5805 - val_accuracy: 0.8257 - lr: 1.0000e-04
Epoch 32/100
369/369 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.8761
Epoch 32: val_loss did not improve from 0.51016
369/369 [==============================] - 159s 430ms/step - loss: 0.4635 - accuracy: 0.8761 - val_loss: 0.5121 - val_accuracy: 0.8471 - lr: 1.0000e-04
Epoch 33/100
369/369 [==============================] - ETA: 0s - loss: 0.4499 - accuracy: 0.8787
Epoch 33: val_loss improved from 0.51016 to 0.50645, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 160s 432ms/step - loss: 0.4499 - accuracy: 0.8787 - val_loss: 0.5065 - val_accuracy: 0.8543 - lr: 1.0000e-04
Epoch 34/100
369/369 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.8830
Epoch 34: val_loss improved from 0.50645 to 0.50381, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 159s 431ms/step - loss: 0.4376 - accuracy: 0.8830 - val_loss: 0.5038 - val_accuracy: 0.8475 - lr: 1.0000e-04
Epoch 35/100
369/369 [==============================] - ETA: 0s - loss: 0.4218 - accuracy: 0.8877
Epoch 35: val_loss did not improve from 0.50381
369/369 [==============================] - 159s 429ms/step - loss: 0.4218 - accuracy: 0.8877 - val_loss: 0.5159 - val_accuracy: 0.8482 - lr: 1.0000e-04
Epoch 36/100
369/369 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.8861
Epoch 36: val_loss improved from 0.50381 to 0.49680, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 159s 430ms/step - loss: 0.4051 - accuracy: 0.8861 - val_loss: 0.4968 - val_accuracy: 0.8522 - lr: 1.0000e-04
Epoch 37/100
369/369 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.8913
Epoch 37: val_loss improved from 0.49680 to 0.46502, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 159s 430ms/step - loss: 0.3963 - accuracy: 0.8913 - val_loss: 0.4650 - val_accuracy: 0.8618 - lr: 1.0000e-04
Epoch 38/100
369/369 [==============================] - ETA: 0s - loss: 0.3956 - accuracy: 0.8914
Epoch 38: val_loss did not improve from 0.46502
369/369 [==============================] - 159s 429ms/step - loss: 0.3956 - accuracy: 0.8914 - val_loss: 0.5602 - val_accuracy: 0.8390 - lr: 1.0000e-04
Epoch 39/100
369/369 [==============================] - ETA: 0s - loss: 0.3649 - accuracy: 0.9028
Epoch 39: val_loss did not improve from 0.46502
369/369 [==============================] - 159s 429ms/step - loss: 0.3649 - accuracy: 0.9028 - val_loss: 0.4893 - val_accuracy: 0.8621 - lr: 1.0000e-04
Epoch 40/100
369/369 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.8981
Epoch 40: val_loss did not improve from 0.46502

Epoch 40: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
369/369 [==============================] - 159s 429ms/step - loss: 0.3743 - accuracy: 0.8981 - val_loss: 0.6298 - val_accuracy: 0.8183 - lr: 1.0000e-04
Epoch 41/100
369/369 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.9144
Epoch 41: val_loss improved from 0.46502 to 0.45450, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 160s 431ms/step - loss: 0.3202 - accuracy: 0.9144 - val_loss: 0.4545 - val_accuracy: 0.8675 - lr: 1.0000e-05
Epoch 42/100
369/369 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.9165
Epoch 42: val_loss improved from 0.45450 to 0.43852, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 160s 431ms/step - loss: 0.3064 - accuracy: 0.9165 - val_loss: 0.4385 - val_accuracy: 0.8743 - lr: 1.0000e-05
Epoch 43/100
369/369 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.9227
Epoch 43: val_loss did not improve from 0.43852
369/369 [==============================] - 158s 427ms/step - loss: 0.2950 - accuracy: 0.9227 - val_loss: 0.4400 - val_accuracy: 0.8750 - lr: 1.0000e-05
Epoch 44/100
369/369 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.9221
Epoch 44: val_loss improved from 0.43852 to 0.40965, saving model to resnet50_saved_2025-04-05_00-47-36.keras
369/369 [==============================] - 159s 430ms/step - loss: 0.2926 - accuracy: 0.9221 - val_loss: 0.4096 - val_accuracy: 0.8845 - lr: 1.0000e-05
Epoch 45/100
369/369 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.9248
Epoch 45: val_loss did not improve from 0.40965
369/369 [==============================] - 159s 431ms/step - loss: 0.2877 - accuracy: 0.9248 - val_loss: 0.4377 - val_accuracy: 0.8777 - lr: 1.0000e-05
Epoch 46/100
369/369 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.9260
Epoch 46: val_loss did not improve from 0.40965
369/369 [==============================] - 159s 429ms/step - loss: 0.2883 - accuracy: 0.9260 - val_loss: 0.4339 - val_accuracy: 0.8774 - lr: 1.0000e-05
Epoch 47/100
369/369 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.9231
Epoch 47: val_loss did not improve from 0.40965

Epoch 47: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
369/369 [==============================] - 159s 429ms/step - loss: 0.2869 - accuracy: 0.9231 - val_loss: 0.4292 - val_accuracy: 0.8794 - lr: 1.0000e-05
Epoch 48/100
369/369 [==============================] - ETA: 0s - loss: 0.2841 - accuracy: 0.9254
Epoch 48: val_loss did not improve from 0.40965
369/369 [==============================] - 158s 427ms/step - loss: 0.2841 - accuracy: 0.9254 - val_loss: 0.4319 - val_accuracy: 0.8798 - lr: 1.0000e-06
Epoch 49/100
369/369 [==============================] - ETA: 0s - loss: 0.2758 - accuracy: 0.9284
Epoch 49: val_loss did not improve from 0.40965
369/369 [==============================] - 158s 428ms/step - loss: 0.2758 - accuracy: 0.9284 - val_loss: 0.4337 - val_accuracy: 0.8825 - lr: 1.0000e-06
Epoch 50/100
369/369 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.9260
Epoch 50: val_loss did not improve from 0.40965

Epoch 50: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.
369/369 [==============================] - 158s 428ms/step - loss: 0.2833 - accuracy: 0.9260 - val_loss: 0.4189 - val_accuracy: 0.8852 - lr: 1.0000e-06
Epoch 51/100
369/369 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.9288
Epoch 51: val_loss did not improve from 0.40965
369/369 [==============================] - 159s 429ms/step - loss: 0.2721 - accuracy: 0.9288 - val_loss: 0.4116 - val_accuracy: 0.8862 - lr: 1.0000e-07
Epoch 52/100
369/369 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.9271
Epoch 52: val_loss did not improve from 0.40965
369/369 [==============================] - 159s 430ms/step - loss: 0.2779 - accuracy: 0.9271 - val_loss: 0.4156 - val_accuracy: 0.8845 - lr: 1.0000e-07
Epoch 53/100
369/369 [==============================] - ETA: 0s - loss: 0.2715 - accuracy: 0.9272
Epoch 53: val_loss did not improve from 0.40965

Epoch 53: ReduceLROnPlateau reducing learning rate to 1e-07.
369/369 [==============================] - 159s 428ms/step - loss: 0.2715 - accuracy: 0.9272 - val_loss: 0.4136 - val_accuracy: 0.8828 - lr: 1.0000e-07
Epoch 54/100
369/369 [==============================] - ETA: 0s - loss: 0.2676 - accuracy: 0.9325
Epoch 54: val_loss did not improve from 0.40965
369/369 [==============================] - 159s 428ms/step - loss: 0.2676 - accuracy: 0.9325 - val_loss: 0.4306 - val_accuracy: 0.8787 - lr: 1.0000e-07
Test Accuracy: 0.9065
115/115 [==============================] - 15s 124ms/step
Classification Report:
              precision    recall  f1-score   support

     battery       0.91      0.88      0.89       260
   cardboard       0.95      0.90      0.93       278
     clothes       0.97      0.95      0.96      1006
       glass       0.94      0.81      0.87       401
       metal       0.80      0.90      0.85       272
     organic       0.94      0.94      0.94       363
       paper       0.83      0.94      0.88       309
     plastic       0.83      0.87      0.85       396
       shoes       0.88      0.89      0.89       395

    accuracy                           0.91      3680
   macro avg       0.90      0.90      0.90      3680
weighted avg       0.91      0.91      0.91      3680

Confusion Matrix: [[229   3   0   1   9   2   5   1  10]
 [  5 250   4   1   1   0   9   5   3]
 [  0   2 956   2   6   3  21  12   4]
 [  1   3   0 326  20   4   6  33   8]
 [  4   0   1   3 246   1   3   8   6]
 [  1   1   3   3   2 341   2   3   7]
 [  1   2   3   0   3   0 291   5   4]
 [  6   0   3   9  16   1  10 346   5]
 [  5   1  12   1   6  10   4   5 351]]

Process finished with exit code 0
