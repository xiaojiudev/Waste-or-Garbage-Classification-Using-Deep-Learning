"C:\Program Files\Python310\python.exe" D:\Study\CNTT\A.MHUD\CNN_Practice\MODEL_MOBILENET.py
2025-03-27 12:09:59.567616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
TensorFlow is using GPU: True
1 Physical GPU, 1 Logical GPUs
2025-03-27 12:10:00.424171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8192 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6
Found 10321 images belonging to 9 classes.
Found 2574 images belonging to 9 classes.
Found 5521 images belonging to 9 classes.
Training class distribution: Counter({2: 2820, 3: 1124, 7: 1112, 8: 1108, 5: 1020, 6: 868, 1: 779, 4: 762, 0: 728})
Validation class distribution: Counter({2: 704, 3: 281, 7: 277, 8: 276, 5: 254, 6: 216, 1: 194, 4: 190, 0: 182})
Testing class distribution: Counter({2: 1509, 3: 602, 7: 594, 8: 592, 5: 545, 6: 464, 1: 417, 4: 408, 0: 390})
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.9640274..0.99558675].
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 224, 224, 3  0           []
                                )]

 Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']
                                )

 bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']
                                )

 Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']
                                )

 expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']
 wiseConv2D)                    )

 expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']
 tchNormalization)              )

 expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0
 ReLU)                          )                                ]']

 expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]
                                )                                [0]']

 expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']
 hNormalization)                )

 block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'
                                )                                ]

 block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']
 ization)                       )

 block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']
                                )

 block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']
                                )

 block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']
 nv2D)

 block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']
 malization)

 block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']

 block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]']

 block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']
 lization)

 block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']

 block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']
 ization)

 block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']

 block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']
 nv2D)

 block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']
 malization)

 block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']

 block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]']

 block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']
 lization)

 block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',
                                                                  'block_2_project_BN[0][0]']

 block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']

 block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']
 ization)

 block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']

 block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']

 block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']
 nv2D)

 block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']
 malization)

 block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']

 block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]']

 block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']
 lization)

 block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']

 block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']
 ization)

 block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']

 block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']
 nv2D)

 block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']
 malization)

 block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']

 block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]']

 block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']
 lization)

 block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',
                                                                  'block_4_project_BN[0][0]']

 block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']

 block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']
 ization)

 block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']

 block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']
 nv2D)

 block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']
 malization)

 block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']

 block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]']

 block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']
 lization)

 block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',
                                                                  'block_5_project_BN[0][0]']

 block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']

 block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']
 ization)

 block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']

 block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']

 block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']
 nv2D)

 block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']
 malization)

 block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']

 block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]']

 block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']
 lization)

 block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']

 block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']
 ization)

 block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']

 block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']
 nv2D)

 block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']
 malization)

 block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']

 block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]']

 block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']
 lization)

 block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',
                                                                  'block_7_project_BN[0][0]']

 block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']

 block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']
 ization)

 block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']

 block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']
 nv2D)

 block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']
 malization)

 block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']

 block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]']

 block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']
 lization)

 block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',
                                                                  'block_8_project_BN[0][0]']

 block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']

 block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']
 ization)

 block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']

 block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']
 nv2D)

 block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']
 malization)

 block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']

 block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]']

 block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']
 lization)

 block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',
                                                                  'block_9_project_BN[0][0]']

 block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']

 block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']
 lization)

 block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']

 block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']
 onv2D)

 block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']
 rmalization)

 block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']

 block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']

 block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']
 alization)

 block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']

 block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']
 lization)

 block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']

 block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']
 onv2D)

 block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']
 rmalization)

 block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']

 block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']

 block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']
 alization)

 block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',
                                                                  'block_11_project_BN[0][0]']

 block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']

 block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']
 lization)

 block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']

 block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']
 onv2D)

 block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']
 rmalization)

 block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']

 block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']

 block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']
 alization)

 block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',
                                                                  'block_12_project_BN[0][0]']

 block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']

 block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']
 lization)

 block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']

 block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']

 block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']
 onv2D)

 block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']
 rmalization)

 block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']

 block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']

 block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']
 alization)

 block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']

 block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']
 lization)

 block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']

 block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']
 onv2D)

 block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']
 rmalization)

 block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']

 block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']

 block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']
 alization)

 block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',
                                                                  'block_14_project_BN[0][0]']

 block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']

 block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']
 lization)

 block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']

 block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']
 onv2D)

 block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']
 rmalization)

 block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']

 block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']

 block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']
 alization)

 block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',
                                                                  'block_15_project_BN[0][0]']

 block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']

 block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']
 lization)

 block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']

 block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']
 onv2D)

 block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']
 rmalization)

 block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']

 block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']

 block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']
 alization)

 Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']

 Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']

 out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']

 conv2d (Conv2D)                (None, 7, 7, 128)    1474688     ['out_relu[0][0]']

 max_pooling2d (MaxPooling2D)   (None, 3, 3, 128)    0           ['conv2d[0][0]']

 batch_normalization (BatchNorm  (None, 3, 3, 128)   512         ['max_pooling2d[0][0]']
 alization)

 conv2d_1 (Conv2D)              (None, 3, 3, 128)    147584      ['batch_normalization[0][0]']

 max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 128)   0           ['conv2d_1[0][0]']

 batch_normalization_1 (BatchNo  (None, 1, 1, 128)   512         ['max_pooling2d_1[0][0]']
 rmalization)

 flatten (Flatten)              (None, 128)          0           ['batch_normalization_1[0][0]']

 dense (Dense)                  (None, 512)          66048       ['flatten[0][0]']

 batch_normalization_2 (BatchNo  (None, 512)         2048        ['dense[0][0]']
 rmalization)

 dropout (Dropout)              (None, 512)          0           ['batch_normalization_2[0][0]']

 dense_1 (Dense)                (None, 256)          131328      ['dropout[0][0]']

 batch_normalization_3 (BatchNo  (None, 256)         1024        ['dense_1[0][0]']
 rmalization)

 dropout_1 (Dropout)            (None, 256)          0           ['batch_normalization_3[0][0]']

 dense_2 (Dense)                (None, 128)          32896       ['dropout_1[0][0]']

 batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_2[0][0]']
 rmalization)

 dropout_2 (Dropout)            (None, 128)          0           ['batch_normalization_4[0][0]']

 dense_3 (Dense)                (None, 9)            1161        ['dropout_2[0][0]']

==================================================================================================
Total params: 4,116,297
Trainable params: 4,079,881
Non-trainable params: 36,416
__________________________________________________________________________________________________
Epoch 1/100
2025-03-27 12:10:10.590966: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8907
2025-03-27 12:10:11.981375: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
191/323 [================>.............] - ETA: 30s - loss: 2.4856 - accuracy: 0.4579C:\Program Files\Python310\lib\site-packages\PIL\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
323/323 [==============================] - ETA: 0s - loss: 2.1797 - accuracy: 0.5561
Epoch 1: val_loss improved from inf to 4.23151, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 108s 310ms/step - loss: 2.1797 - accuracy: 0.5561 - val_loss: 4.2315 - val_accuracy: 0.1721 - lr: 0.0010
Epoch 2/100
323/323 [==============================] - ETA: 0s - loss: 1.4074 - accuracy: 0.7900
Epoch 2: val_loss improved from 4.23151 to 3.13327, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 94s 291ms/step - loss: 1.4074 - accuracy: 0.7900 - val_loss: 3.1333 - val_accuracy: 0.3866 - lr: 0.0010
Epoch 3/100
323/323 [==============================] - ETA: 0s - loss: 1.2207 - accuracy: 0.8281
Epoch 3: val_loss did not improve from 3.13327
323/323 [==============================] - 98s 301ms/step - loss: 1.2207 - accuracy: 0.8281 - val_loss: 3.9040 - val_accuracy: 0.3780 - lr: 0.0010
Epoch 4/100
323/323 [==============================] - ETA: 0s - loss: 1.0745 - accuracy: 0.8380
Epoch 4: val_loss did not improve from 3.13327
323/323 [==============================] - 96s 295ms/step - loss: 1.0745 - accuracy: 0.8380 - val_loss: 3.1634 - val_accuracy: 0.3547 - lr: 0.0010
Epoch 5/100
323/323 [==============================] - ETA: 0s - loss: 0.9806 - accuracy: 0.8474
Epoch 5: val_loss did not improve from 3.13327

Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
323/323 [==============================] - 94s 291ms/step - loss: 0.9806 - accuracy: 0.8474 - val_loss: 3.1364 - val_accuracy: 0.4274 - lr: 0.0010
Epoch 6/100
323/323 [==============================] - ETA: 0s - loss: 0.7428 - accuracy: 0.8980
Epoch 6: val_loss improved from 3.13327 to 1.47722, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 97s 298ms/step - loss: 0.7428 - accuracy: 0.8980 - val_loss: 1.4772 - val_accuracy: 0.7051 - lr: 1.0000e-04
Epoch 7/100
323/323 [==============================] - ETA: 0s - loss: 0.6561 - accuracy: 0.9207
Epoch 7: val_loss improved from 1.47722 to 0.90786, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 103s 317ms/step - loss: 0.6561 - accuracy: 0.9207 - val_loss: 0.9079 - val_accuracy: 0.8392 - lr: 1.0000e-04
Epoch 8/100
323/323 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.9304
Epoch 8: val_loss improved from 0.90786 to 0.72525, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 94s 291ms/step - loss: 0.6135 - accuracy: 0.9304 - val_loss: 0.7252 - val_accuracy: 0.8869 - lr: 1.0000e-04
Epoch 9/100
323/323 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.9367
Epoch 9: val_loss improved from 0.72525 to 0.67218, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 96s 295ms/step - loss: 0.5669 - accuracy: 0.9367 - val_loss: 0.6722 - val_accuracy: 0.8970 - lr: 1.0000e-04
Epoch 10/100
323/323 [==============================] - ETA: 0s - loss: 0.5551 - accuracy: 0.9405
Epoch 10: val_loss improved from 0.67218 to 0.60227, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 96s 296ms/step - loss: 0.5551 - accuracy: 0.9405 - val_loss: 0.6023 - val_accuracy: 0.9122 - lr: 1.0000e-04
Epoch 11/100
323/323 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.9466
Epoch 11: val_loss improved from 0.60227 to 0.58168, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 96s 295ms/step - loss: 0.5112 - accuracy: 0.9466 - val_loss: 0.5817 - val_accuracy: 0.9180 - lr: 1.0000e-04
Epoch 12/100
323/323 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.9509
Epoch 12: val_loss did not improve from 0.58168
323/323 [==============================] - 94s 291ms/step - loss: 0.4838 - accuracy: 0.9509 - val_loss: 0.6203 - val_accuracy: 0.9091 - lr: 1.0000e-04
Epoch 13/100
323/323 [==============================] - ETA: 0s - loss: 0.4596 - accuracy: 0.9525
Epoch 13: val_loss improved from 0.58168 to 0.56105, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 95s 294ms/step - loss: 0.4596 - accuracy: 0.9525 - val_loss: 0.5611 - val_accuracy: 0.9149 - lr: 1.0000e-04
Epoch 14/100
323/323 [==============================] - ETA: 0s - loss: 0.4317 - accuracy: 0.9584
Epoch 14: val_loss improved from 0.56105 to 0.55927, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 92s 283ms/step - loss: 0.4317 - accuracy: 0.9584 - val_loss: 0.5593 - val_accuracy: 0.9138 - lr: 1.0000e-04
Epoch 15/100
323/323 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.9592
Epoch 15: val_loss improved from 0.55927 to 0.53160, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 94s 291ms/step - loss: 0.4053 - accuracy: 0.9592 - val_loss: 0.5316 - val_accuracy: 0.9223 - lr: 1.0000e-04
Epoch 16/100
323/323 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.9641
Epoch 16: val_loss did not improve from 0.53160
323/323 [==============================] - 96s 295ms/step - loss: 0.3813 - accuracy: 0.9641 - val_loss: 0.5507 - val_accuracy: 0.9095 - lr: 1.0000e-04
Epoch 17/100
323/323 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.9631
Epoch 17: val_loss improved from 0.53160 to 0.46903, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 96s 295ms/step - loss: 0.3739 - accuracy: 0.9631 - val_loss: 0.4690 - val_accuracy: 0.9308 - lr: 1.0000e-04
Epoch 18/100
323/323 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.9642
Epoch 18: val_loss did not improve from 0.46903
323/323 [==============================] - 95s 294ms/step - loss: 0.3517 - accuracy: 0.9642 - val_loss: 0.4818 - val_accuracy: 0.9285 - lr: 1.0000e-04
Epoch 19/100
323/323 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.9693
Epoch 19: val_loss did not improve from 0.46903
323/323 [==============================] - 94s 290ms/step - loss: 0.3257 - accuracy: 0.9693 - val_loss: 0.4712 - val_accuracy: 0.9281 - lr: 1.0000e-04
Epoch 20/100
323/323 [==============================] - ETA: 0s - loss: 0.3105 - accuracy: 0.9705
Epoch 20: val_loss improved from 0.46903 to 0.46191, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 94s 289ms/step - loss: 0.3105 - accuracy: 0.9705 - val_loss: 0.4619 - val_accuracy: 0.9301 - lr: 1.0000e-04
Epoch 21/100
323/323 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.9697
Epoch 21: val_loss improved from 0.46191 to 0.45162, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 95s 292ms/step - loss: 0.3015 - accuracy: 0.9697 - val_loss: 0.4516 - val_accuracy: 0.9277 - lr: 1.0000e-04
Epoch 22/100
323/323 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.9716
Epoch 22: val_loss improved from 0.45162 to 0.43485, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 95s 293ms/step - loss: 0.2853 - accuracy: 0.9716 - val_loss: 0.4349 - val_accuracy: 0.9359 - lr: 1.0000e-04
Epoch 23/100
323/323 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.9746
Epoch 23: val_loss did not improve from 0.43485
323/323 [==============================] - 95s 293ms/step - loss: 0.2624 - accuracy: 0.9746 - val_loss: 0.4618 - val_accuracy: 0.9227 - lr: 1.0000e-04
Epoch 24/100
323/323 [==============================] - ETA: 0s - loss: 0.2553 - accuracy: 0.9743
Epoch 24: val_loss did not improve from 0.43485
323/323 [==============================] - 96s 295ms/step - loss: 0.2553 - accuracy: 0.9743 - val_loss: 0.4606 - val_accuracy: 0.9235 - lr: 1.0000e-04
Epoch 25/100
323/323 [==============================] - ETA: 0s - loss: 0.2572 - accuracy: 0.9715
Epoch 25: val_loss improved from 0.43485 to 0.40593, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 110s 340ms/step - loss: 0.2572 - accuracy: 0.9715 - val_loss: 0.4059 - val_accuracy: 0.9343 - lr: 1.0000e-04
Epoch 26/100
323/323 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.9784
Epoch 26: val_loss did not improve from 0.40593
323/323 [==============================] - 93s 285ms/step - loss: 0.2283 - accuracy: 0.9784 - val_loss: 0.4700 - val_accuracy: 0.9180 - lr: 1.0000e-04
Epoch 27/100
323/323 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.9785
Epoch 27: val_loss did not improve from 0.40593
323/323 [==============================] - 93s 287ms/step - loss: 0.2229 - accuracy: 0.9785 - val_loss: 0.4213 - val_accuracy: 0.9308 - lr: 1.0000e-04
Epoch 28/100
323/323 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.9787
Epoch 28: val_loss did not improve from 0.40593

Epoch 28: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
323/323 [==============================] - 96s 295ms/step - loss: 0.2183 - accuracy: 0.9787 - val_loss: 0.4287 - val_accuracy: 0.9231 - lr: 1.0000e-04
Epoch 29/100
323/323 [==============================] - ETA: 0s - loss: 0.1949 - accuracy: 0.9827
Epoch 29: val_loss did not improve from 0.40593
323/323 [==============================] - 96s 296ms/step - loss: 0.1949 - accuracy: 0.9827 - val_loss: 0.4114 - val_accuracy: 0.9332 - lr: 1.0000e-05
Epoch 30/100
323/323 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9877
Epoch 30: val_loss improved from 0.40593 to 0.36465, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 96s 296ms/step - loss: 0.1781 - accuracy: 0.9877 - val_loss: 0.3647 - val_accuracy: 0.9437 - lr: 1.0000e-05
Epoch 31/100
323/323 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.9852
Epoch 31: val_loss improved from 0.36465 to 0.33784, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 96s 296ms/step - loss: 0.1820 - accuracy: 0.9852 - val_loss: 0.3378 - val_accuracy: 0.9476 - lr: 1.0000e-05
Epoch 32/100
323/323 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.9891
Epoch 32: val_loss did not improve from 0.33784
323/323 [==============================] - 95s 292ms/step - loss: 0.1753 - accuracy: 0.9891 - val_loss: 0.3557 - val_accuracy: 0.9448 - lr: 1.0000e-05
Epoch 33/100
323/323 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.9882
Epoch 33: val_loss did not improve from 0.33784
323/323 [==============================] - 95s 293ms/step - loss: 0.1731 - accuracy: 0.9882 - val_loss: 0.3517 - val_accuracy: 0.9452 - lr: 1.0000e-05
Epoch 34/100
323/323 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9885
Epoch 34: val_loss improved from 0.33784 to 0.33650, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 97s 300ms/step - loss: 0.1681 - accuracy: 0.9885 - val_loss: 0.3365 - val_accuracy: 0.9468 - lr: 1.0000e-05
Epoch 35/100
323/323 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.9908
Epoch 35: val_loss improved from 0.33650 to 0.33321, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 97s 300ms/step - loss: 0.1633 - accuracy: 0.9908 - val_loss: 0.3332 - val_accuracy: 0.9503 - lr: 1.0000e-05
Epoch 36/100
323/323 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.9905
Epoch 36: val_loss did not improve from 0.33321
323/323 [==============================] - 93s 287ms/step - loss: 0.1634 - accuracy: 0.9905 - val_loss: 0.3521 - val_accuracy: 0.9460 - lr: 1.0000e-05
Epoch 37/100
323/323 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.9934
Epoch 37: val_loss improved from 0.33321 to 0.33200, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 93s 288ms/step - loss: 0.1544 - accuracy: 0.9934 - val_loss: 0.3320 - val_accuracy: 0.9495 - lr: 1.0000e-05
Epoch 38/100
323/323 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.9910
Epoch 38: val_loss improved from 0.33200 to 0.32684, saving model to mobilenet_saved_2025-03-27_12-10-00.keras
323/323 [==============================] - 96s 295ms/step - loss: 0.1614 - accuracy: 0.9910 - val_loss: 0.3268 - val_accuracy: 0.9503 - lr: 1.0000e-05
Epoch 39/100
323/323 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9922
Epoch 39: val_loss did not improve from 0.32684
323/323 [==============================] - 96s 296ms/step - loss: 0.1565 - accuracy: 0.9922 - val_loss: 0.3295 - val_accuracy: 0.9514 - lr: 1.0000e-05
Epoch 40/100
323/323 [==============================] - ETA: 0s - loss: 0.1507 - accuracy: 0.9938
Epoch 40: val_loss did not improve from 0.32684
323/323 [==============================] - 96s 296ms/step - loss: 0.1507 - accuracy: 0.9938 - val_loss: 0.3367 - val_accuracy: 0.9514 - lr: 1.0000e-05
Epoch 41/100
323/323 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.9908
Epoch 41: val_loss did not improve from 0.32684

Epoch 41: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
323/323 [==============================] - 96s 298ms/step - loss: 0.1563 - accuracy: 0.9908 - val_loss: 0.3522 - val_accuracy: 0.9472 - lr: 1.0000e-05
Epoch 42/100
323/323 [==============================] - ETA: 0s - loss: 0.1521 - accuracy: 0.9915
Epoch 42: val_loss did not improve from 0.32684
323/323 [==============================] - 96s 297ms/step - loss: 0.1521 - accuracy: 0.9915 - val_loss: 0.3468 - val_accuracy: 0.9460 - lr: 1.0000e-06
Epoch 43/100
323/323 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.9923
Epoch 43: val_loss did not improve from 0.32684
323/323 [==============================] - 95s 294ms/step - loss: 0.1503 - accuracy: 0.9923 - val_loss: 0.3462 - val_accuracy: 0.9487 - lr: 1.0000e-06
Epoch 44/100
323/323 [==============================] - ETA: 0s - loss: 0.1486 - accuracy: 0.9931
Epoch 44: val_loss did not improve from 0.32684

Epoch 44: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.
323/323 [==============================] - 96s 297ms/step - loss: 0.1486 - accuracy: 0.9931 - val_loss: 0.3508 - val_accuracy: 0.9448 - lr: 1.0000e-06
Epoch 45/100
323/323 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.9914
Epoch 45: val_loss did not improve from 0.32684
323/323 [==============================] - 95s 294ms/step - loss: 0.1532 - accuracy: 0.9914 - val_loss: 0.3472 - val_accuracy: 0.9456 - lr: 1.0000e-07
Epoch 46/100
323/323 [==============================] - ETA: 0s - loss: 0.1521 - accuracy: 0.9921
Epoch 46: val_loss did not improve from 0.32684
323/323 [==============================] - 96s 295ms/step - loss: 0.1521 - accuracy: 0.9921 - val_loss: 0.3368 - val_accuracy: 0.9495 - lr: 1.0000e-07
Epoch 47/100
323/323 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.9916
Epoch 47: val_loss did not improve from 0.32684

Epoch 47: ReduceLROnPlateau reducing learning rate to 1e-07.
323/323 [==============================] - 96s 297ms/step - loss: 0.1532 - accuracy: 0.9916 - val_loss: 0.3319 - val_accuracy: 0.9464 - lr: 1.0000e-07
Epoch 48/100
323/323 [==============================] - ETA: 0s - loss: 0.1496 - accuracy: 0.9931
Epoch 48: val_loss did not improve from 0.32684
323/323 [==============================] - 96s 297ms/step - loss: 0.1496 - accuracy: 0.9931 - val_loss: 0.3362 - val_accuracy: 0.9514 - lr: 1.0000e-07
Test Accuracy: 0.9598
173/173 [==============================] - 11s 58ms/step
Classification Report:
              precision    recall  f1-score   support

     battery       0.96      0.96      0.96       390
   cardboard       0.97      0.94      0.96       417
     clothes       0.99      0.99      0.99      1509
       glass       0.95      0.93      0.94       602
       metal       0.89      0.93      0.91       408
     organic       0.98      0.95      0.97       545
       paper       0.93      0.97      0.95       464
     plastic       0.93      0.91      0.92       594
       shoes       0.96      0.99      0.97       592

    accuracy                           0.96      5521
   macro avg       0.95      0.95      0.95      5521
weighted avg       0.96      0.96      0.96      5521

Confusion Matrix: [[ 375    0    0    3    3    2    4    2    1]
 [   4  394    3    2    2    0    9    3    0]
 [   0    0 1499    1    3    0    4    0    2]
 [   2    0    1  557   15    4    2   21    0]
 [   4    3    0    1  380    2    1    9    8]
 [   1    0    4    4    3  518    2    4    9]
 [   0    8    1    0    3    0  449    3    0]
 [   3    1    0   18   16    1    9  543    3]
 [   0    0    1    3    0    1    1    2  584]]

Process finished with exit code 0

27-03-2025-17-06

"C:\Program Files\Python310\python.exe" D:\Study\CNTT\A.MHUD\CNN_Practice\MODEL_MOBILENET.py
GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
TensorFlow is using GPU: True
2025-03-27 20:21:13.287301: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
1 Physical GPU, 1 Logical GPUs
2025-03-27 20:21:13.760358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8192 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6
Found 10321 images belonging to 9 classes.
Found 2574 images belonging to 9 classes.
Found 5521 images belonging to 9 classes.
Training class distribution: Counter({2: 2820, 3: 1124, 7: 1112, 8: 1108, 5: 1020, 6: 868, 1: 779, 4: 762, 0: 728})
Validation class distribution: Counter({2: 704, 3: 281, 7: 277, 8: 276, 5: 254, 6: 216, 1: 194, 4: 190, 0: 182})
Testing class distribution: Counter({2: 1509, 3: 602, 7: 594, 8: 592, 5: 545, 6: 464, 1: 417, 4: 408, 0: 390})
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..1.0].
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 224, 224, 3  0           []
                                )]

 Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']
                                )

 bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']
                                )

 Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']
                                )

 expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']
 wiseConv2D)                    )

 expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']
 tchNormalization)              )

 expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0
 ReLU)                          )                                ]']

 expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]
                                )                                [0]']

 expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']
 hNormalization)                )

 block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'
                                )                                ]

 block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']
 ization)                       )

 block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']
                                )

 block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']
                                )

 block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']
 nv2D)

 block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']
 malization)

 block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']

 block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]']

 block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']
 lization)

 block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']

 block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']
 ization)

 block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']

 block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']
 nv2D)

 block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']
 malization)

 block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']

 block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]']

 block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']
 lization)

 block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',
                                                                  'block_2_project_BN[0][0]']

 block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']

 block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']
 ization)

 block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']

 block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']

 block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']
 nv2D)

 block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']
 malization)

 block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']

 block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]']

 block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']
 lization)

 block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']

 block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']
 ization)

 block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']

 block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']
 nv2D)

 block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']
 malization)

 block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']

 block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]']

 block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']
 lization)

 block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',
                                                                  'block_4_project_BN[0][0]']

 block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']

 block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']
 ization)

 block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']

 block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']
 nv2D)

 block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']
 malization)

 block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']

 block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]']

 block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']
 lization)

 block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',
                                                                  'block_5_project_BN[0][0]']

 block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']

 block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']
 ization)

 block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']

 block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']

 block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']
 nv2D)

 block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']
 malization)

 block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']

 block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]']

 block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']
 lization)

 block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']

 block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']
 ization)

 block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']

 block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']
 nv2D)

 block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']
 malization)

 block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']

 block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]']

 block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']
 lization)

 block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',
                                                                  'block_7_project_BN[0][0]']

 block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']

 block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']
 ization)

 block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']

 block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']
 nv2D)

 block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']
 malization)

 block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']

 block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]']

 block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']
 lization)

 block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',
                                                                  'block_8_project_BN[0][0]']

 block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']

 block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']
 ization)

 block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']

 block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']
 nv2D)

 block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']
 malization)

 block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']

 block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]']

 block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']
 lization)

 block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',
                                                                  'block_9_project_BN[0][0]']

 block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']

 block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']
 lization)

 block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']

 block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']
 onv2D)

 block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']
 rmalization)

 block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']

 block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']

 block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']
 alization)

 block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']

 block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']
 lization)

 block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']

 block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']
 onv2D)

 block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']
 rmalization)

 block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']

 block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']

 block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']
 alization)

 block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',
                                                                  'block_11_project_BN[0][0]']

 block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']

 block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']
 lization)

 block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']

 block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']
 onv2D)

 block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']
 rmalization)

 block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']

 block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']

 block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']
 alization)

 block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',
                                                                  'block_12_project_BN[0][0]']

 block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']

 block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']
 lization)

 block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']

 block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']

 block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']
 onv2D)

 block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']
 rmalization)

 block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']

 block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']

 block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']
 alization)

 block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']

 block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']
 lization)

 block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']

 block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']
 onv2D)

 block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']
 rmalization)

 block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']

 block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']

 block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']
 alization)

 block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',
                                                                  'block_14_project_BN[0][0]']

 block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']

 block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']
 lization)

 block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']

 block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']
 onv2D)

 block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']
 rmalization)

 block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']

 block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']

 block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']
 alization)

 block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',
                                                                  'block_15_project_BN[0][0]']

 block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']

 block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']
 lization)

 block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']

 block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']
 onv2D)

 block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']
 rmalization)

 block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']

 block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']

 block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']
 alization)

 Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']

 Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']

 out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']

 conv2d (Conv2D)                (None, 7, 7, 128)    1474688     ['out_relu[0][0]']

 max_pooling2d (MaxPooling2D)   (None, 3, 3, 128)    0           ['conv2d[0][0]']

 batch_normalization (BatchNorm  (None, 3, 3, 128)   512         ['max_pooling2d[0][0]']
 alization)

 conv2d_1 (Conv2D)              (None, 3, 3, 128)    147584      ['batch_normalization[0][0]']

 max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 128)   0           ['conv2d_1[0][0]']

 batch_normalization_1 (BatchNo  (None, 1, 1, 128)   512         ['max_pooling2d_1[0][0]']
 rmalization)

 flatten (Flatten)              (None, 128)          0           ['batch_normalization_1[0][0]']

 dense (Dense)                  (None, 512)          66048       ['flatten[0][0]']

 batch_normalization_2 (BatchNo  (None, 512)         2048        ['dense[0][0]']
 rmalization)

 dropout (Dropout)              (None, 512)          0           ['batch_normalization_2[0][0]']

 dense_1 (Dense)                (None, 256)          131328      ['dropout[0][0]']

 batch_normalization_3 (BatchNo  (None, 256)         1024        ['dense_1[0][0]']
 rmalization)

 dropout_1 (Dropout)            (None, 256)          0           ['batch_normalization_3[0][0]']

 dense_2 (Dense)                (None, 128)          32896       ['dropout_1[0][0]']

 batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_2[0][0]']
 rmalization)

 dropout_2 (Dropout)            (None, 128)          0           ['batch_normalization_4[0][0]']

 dense_3 (Dense)                (None, 9)            1161        ['dropout_2[0][0]']

==================================================================================================
Total params: 4,116,297
Trainable params: 4,079,881
Non-trainable params: 36,416
__________________________________________________________________________________________________
Epoch 1/100
2025-03-27 20:21:22.320329: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8907
2025-03-27 20:21:23.113539: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
228/323 [====================>.........] - ETA: 20s - loss: 2.1556 - accuracy: 0.5619C:\Program Files\Python310\lib\site-packages\PIL\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
323/323 [==============================] - ETA: 0s - loss: 1.9806 - accuracy: 0.6197
Epoch 1: val_loss improved from inf to 3.17759, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 99s 287ms/step - loss: 1.9806 - accuracy: 0.6197 - val_loss: 3.1776 - val_accuracy: 0.4095 - lr: 0.0010
Epoch 2/100
323/323 [==============================] - ETA: 0s - loss: 1.3860 - accuracy: 0.7944
Epoch 2: val_loss improved from 3.17759 to 1.97922, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 94s 290ms/step - loss: 1.3860 - accuracy: 0.7944 - val_loss: 1.9792 - val_accuracy: 0.6030 - lr: 0.0010
Epoch 3/100
323/323 [==============================] - ETA: 0s - loss: 1.1905 - accuracy: 0.8288
Epoch 3: val_loss improved from 1.97922 to 1.90387, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 109s 338ms/step - loss: 1.1905 - accuracy: 0.8288 - val_loss: 1.9039 - val_accuracy: 0.6084 - lr: 0.0010
Epoch 4/100
323/323 [==============================] - ETA: 0s - loss: 1.0597 - accuracy: 0.8440
Epoch 4: val_loss did not improve from 1.90387
323/323 [==============================] - 110s 340ms/step - loss: 1.0597 - accuracy: 0.8440 - val_loss: 3.2721 - val_accuracy: 0.4409 - lr: 0.0010
Epoch 5/100
323/323 [==============================] - ETA: 0s - loss: 0.9542 - accuracy: 0.8494
Epoch 5: val_loss did not improve from 1.90387
323/323 [==============================] - 110s 340ms/step - loss: 0.9542 - accuracy: 0.8494 - val_loss: 3.6510 - val_accuracy: 0.3656 - lr: 0.0010
Epoch 6/100
323/323 [==============================] - ETA: 0s - loss: 0.8438 - accuracy: 0.8616
Epoch 6: val_loss did not improve from 1.90387

Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
323/323 [==============================] - 109s 338ms/step - loss: 0.8438 - accuracy: 0.8616 - val_loss: 3.0842 - val_accuracy: 0.3912 - lr: 0.0010
Epoch 7/100
323/323 [==============================] - ETA: 0s - loss: 0.6376 - accuracy: 0.9084
Epoch 7: val_loss improved from 1.90387 to 1.15538, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 111s 342ms/step - loss: 0.6376 - accuracy: 0.9084 - val_loss: 1.1554 - val_accuracy: 0.7506 - lr: 1.0000e-04
Epoch 8/100
323/323 [==============================] - ETA: 0s - loss: 0.5583 - accuracy: 0.9281
Epoch 8: val_loss improved from 1.15538 to 0.73451, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 111s 341ms/step - loss: 0.5583 - accuracy: 0.9281 - val_loss: 0.7345 - val_accuracy: 0.8695 - lr: 1.0000e-04
Epoch 9/100
323/323 [==============================] - ETA: 0s - loss: 0.5100 - accuracy: 0.9373
Epoch 9: val_loss improved from 0.73451 to 0.59349, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 110s 341ms/step - loss: 0.5100 - accuracy: 0.9373 - val_loss: 0.5935 - val_accuracy: 0.9064 - lr: 1.0000e-04
Epoch 10/100
323/323 [==============================] - ETA: 0s - loss: 0.4691 - accuracy: 0.9441
Epoch 10: val_loss improved from 0.59349 to 0.57116, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 110s 340ms/step - loss: 0.4691 - accuracy: 0.9441 - val_loss: 0.5712 - val_accuracy: 0.9110 - lr: 1.0000e-04
Epoch 11/100
323/323 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.9496
Epoch 11: val_loss improved from 0.57116 to 0.51392, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 110s 339ms/step - loss: 0.4400 - accuracy: 0.9496 - val_loss: 0.5139 - val_accuracy: 0.9250 - lr: 1.0000e-04
Epoch 12/100
323/323 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.9491
Epoch 12: val_loss did not improve from 0.51392
323/323 [==============================] - 108s 335ms/step - loss: 0.4334 - accuracy: 0.9491 - val_loss: 0.5174 - val_accuracy: 0.9176 - lr: 1.0000e-04
Epoch 13/100
323/323 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.9532
Epoch 13: val_loss improved from 0.51392 to 0.49297, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 111s 343ms/step - loss: 0.3964 - accuracy: 0.9532 - val_loss: 0.4930 - val_accuracy: 0.9270 - lr: 1.0000e-04
Epoch 14/100
323/323 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.9622
Epoch 14: val_loss improved from 0.49297 to 0.45784, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 110s 339ms/step - loss: 0.3623 - accuracy: 0.9622 - val_loss: 0.4578 - val_accuracy: 0.9312 - lr: 1.0000e-04
Epoch 15/100
323/323 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.9617
Epoch 15: val_loss did not improve from 0.45784
323/323 [==============================] - 109s 335ms/step - loss: 0.3501 - accuracy: 0.9617 - val_loss: 0.4673 - val_accuracy: 0.9270 - lr: 1.0000e-04
Epoch 16/100
323/323 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.9650
Epoch 16: val_loss improved from 0.45784 to 0.41485, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 109s 336ms/step - loss: 0.3262 - accuracy: 0.9650 - val_loss: 0.4149 - val_accuracy: 0.9382 - lr: 1.0000e-04
Epoch 17/100
323/323 [==============================] - ETA: 0s - loss: 0.3158 - accuracy: 0.9664
Epoch 17: val_loss did not improve from 0.41485
323/323 [==============================] - 109s 337ms/step - loss: 0.3158 - accuracy: 0.9664 - val_loss: 0.4449 - val_accuracy: 0.9305 - lr: 1.0000e-04
Epoch 18/100
323/323 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.9661
Epoch 18: val_loss did not improve from 0.41485
323/323 [==============================] - 108s 334ms/step - loss: 0.2945 - accuracy: 0.9661 - val_loss: 0.4976 - val_accuracy: 0.9184 - lr: 1.0000e-04
Epoch 19/100
323/323 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.9656
Epoch 19: val_loss did not improve from 0.41485

Epoch 19: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
323/323 [==============================] - 109s 335ms/step - loss: 0.2922 - accuracy: 0.9656 - val_loss: 0.4569 - val_accuracy: 0.9227 - lr: 1.0000e-04
Epoch 20/100
323/323 [==============================] - ETA: 0s - loss: 0.2531 - accuracy: 0.9754
Epoch 20: val_loss did not improve from 0.41485
323/323 [==============================] - 109s 337ms/step - loss: 0.2531 - accuracy: 0.9754 - val_loss: 0.4242 - val_accuracy: 0.9367 - lr: 1.0000e-05
Epoch 21/100
323/323 [==============================] - ETA: 0s - loss: 0.2463 - accuracy: 0.9774
Epoch 21: val_loss improved from 0.41485 to 0.39271, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 109s 337ms/step - loss: 0.2463 - accuracy: 0.9774 - val_loss: 0.3927 - val_accuracy: 0.9363 - lr: 1.0000e-05
Epoch 22/100
323/323 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.9808
Epoch 22: val_loss improved from 0.39271 to 0.37984, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 109s 335ms/step - loss: 0.2373 - accuracy: 0.9808 - val_loss: 0.3798 - val_accuracy: 0.9409 - lr: 1.0000e-05
Epoch 23/100
323/323 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.9812
Epoch 23: val_loss improved from 0.37984 to 0.37915, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 109s 335ms/step - loss: 0.2299 - accuracy: 0.9812 - val_loss: 0.3792 - val_accuracy: 0.9413 - lr: 1.0000e-05
Epoch 24/100
323/323 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.9827
Epoch 24: val_loss did not improve from 0.37915
323/323 [==============================] - 107s 331ms/step - loss: 0.2231 - accuracy: 0.9827 - val_loss: 0.3824 - val_accuracy: 0.9409 - lr: 1.0000e-05
Epoch 25/100
323/323 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9831
Epoch 25: val_loss improved from 0.37915 to 0.36569, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 108s 334ms/step - loss: 0.2235 - accuracy: 0.9831 - val_loss: 0.3657 - val_accuracy: 0.9464 - lr: 1.0000e-05
Epoch 26/100
323/323 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9817
Epoch 26: val_loss did not improve from 0.36569
323/323 [==============================] - 107s 329ms/step - loss: 0.2224 - accuracy: 0.9817 - val_loss: 0.3671 - val_accuracy: 0.9452 - lr: 1.0000e-05
Epoch 27/100
323/323 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.9852
Epoch 27: val_loss improved from 0.36569 to 0.35153, saving model to mobilenet_saved_2025-03-27_20-21-14.keras
323/323 [==============================] - 107s 329ms/step - loss: 0.2132 - accuracy: 0.9852 - val_loss: 0.3515 - val_accuracy: 0.9483 - lr: 1.0000e-05
Epoch 28/100
323/323 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9832
Epoch 28: val_loss did not improve from 0.35153
323/323 [==============================] - 107s 329ms/step - loss: 0.2167 - accuracy: 0.9832 - val_loss: 0.3608 - val_accuracy: 0.9452 - lr: 1.0000e-05
Epoch 29/100
323/323 [==============================] - ETA: 0s - loss: 0.2126 - accuracy: 0.9834
Epoch 29: val_loss did not improve from 0.35153
323/323 [==============================] - 107s 330ms/step - loss: 0.2126 - accuracy: 0.9834 - val_loss: 0.3581 - val_accuracy: 0.9468 - lr: 1.0000e-05
Epoch 30/100
323/323 [==============================] - ETA: 0s - loss: 0.2076 - accuracy: 0.9859
Epoch 30: val_loss improved from 0.35153 to 0.35142, saving model to mobilenet_saved_2025-03-27_20-21-14.keras

Epoch 30: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
323/323 [==============================] - 109s 335ms/step - loss: 0.2076 - accuracy: 0.9859 - val_loss: 0.3514 - val_accuracy: 0.9464 - lr: 1.0000e-05
Epoch 31/100
323/323 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9864
Epoch 31: val_loss did not improve from 0.35142
323/323 [==============================] - 107s 330ms/step - loss: 0.2049 - accuracy: 0.9864 - val_loss: 0.3581 - val_accuracy: 0.9476 - lr: 1.0000e-06
Epoch 32/100
323/323 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9866
Epoch 32: val_loss did not improve from 0.35142
323/323 [==============================] - 107s 330ms/step - loss: 0.2021 - accuracy: 0.9866 - val_loss: 0.3588 - val_accuracy: 0.9472 - lr: 1.0000e-06
Epoch 33/100
323/323 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.9859
Epoch 33: val_loss did not improve from 0.35142

Epoch 33: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.
323/323 [==============================] - 109s 336ms/step - loss: 0.2043 - accuracy: 0.9859 - val_loss: 0.3661 - val_accuracy: 0.9433 - lr: 1.0000e-06
Epoch 34/100
323/323 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.9851
Epoch 34: val_loss did not improve from 0.35142
323/323 [==============================] - 107s 330ms/step - loss: 0.2066 - accuracy: 0.9851 - val_loss: 0.3648 - val_accuracy: 0.9433 - lr: 1.0000e-07
Epoch 35/100
323/323 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.9870
Epoch 35: val_loss did not improve from 0.35142
323/323 [==============================] - 94s 291ms/step - loss: 0.2023 - accuracy: 0.9870 - val_loss: 0.3631 - val_accuracy: 0.9448 - lr: 1.0000e-07
Epoch 36/100
323/323 [==============================] - ETA: 0s - loss: 0.2053 - accuracy: 0.9859
Epoch 36: val_loss did not improve from 0.35142

Epoch 36: ReduceLROnPlateau reducing learning rate to 1e-07.
323/323 [==============================] - 91s 282ms/step - loss: 0.2053 - accuracy: 0.9859 - val_loss: 0.3818 - val_accuracy: 0.9406 - lr: 1.0000e-07
Epoch 37/100
323/323 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.9852
Epoch 37: val_loss did not improve from 0.35142
323/323 [==============================] - 94s 291ms/step - loss: 0.2057 - accuracy: 0.9852 - val_loss: 0.3668 - val_accuracy: 0.9417 - lr: 1.0000e-07
Test Accuracy: 0.9578
173/173 [==============================] - 10s 56ms/step
Classification Report:
              precision    recall  f1-score   support

     battery       0.97      0.97      0.97       390
   cardboard       0.96      0.92      0.94       417
     clothes       1.00      0.99      0.99      1509
       glass       0.93      0.92      0.93       602
       metal       0.92      0.94      0.93       408
     organic       0.98      0.95      0.96       545
       paper       0.91      0.97      0.94       464
     plastic       0.93      0.91      0.92       594
       shoes       0.95      0.98      0.96       592

    accuracy                           0.96      5521
   macro avg       0.95      0.95      0.95      5521
weighted avg       0.96      0.96      0.96      5521

Confusion Matrix: [[ 380    0    1    2    3    0    2    1    1]
 [   3  384    1    3    1    0   20    4    1]
 [   1    0 1499    0    0    0    6    0    3]
 [   1    1    0  554   15    3    2   25    1]
 [   4    2    0    3  383    5    2    3    6]
 [   0    2    2    5    1  516    2    4   13]
 [   1    7    0    0    1    0  451    3    1]
 [   2    1    1   22   13    2    8  542    3]
 [   0    1    2    4    1    1    2    2  579]]

Process finished with exit code 0

04-04-2025-17-06
"C:\Program Files\Python310\python.exe" D:\Study\CNTT\A.MHUD\CNN_Practice\MODEL_MOBILENET.py
2025-04-04 13:41:53.460001: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
TensorFlow is using GPU: True
2025-04-04 13:41:54.382096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8192 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6
1 Physical GPU, 1 Logical GPUs
Found 11792 images belonging to 9 classes.
Found 2944 images belonging to 9 classes.
Found 3680 images belonging to 9 classes.
Training class distribution: Counter({2: 3222, 3: 1285, 7: 1270, 8: 1265, 5: 1165, 6: 992, 1: 890, 4: 871, 0: 832})
Validation class distribution: Counter({2: 805, 3: 321, 7: 317, 8: 316, 5: 291, 6: 247, 1: 222, 4: 217, 0: 208})
Testing class distribution: Counter({2: 1006, 3: 401, 7: 396, 8: 395, 5: 363, 6: 309, 1: 278, 4: 272, 0: 260})
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.9964433..0.95359194].
Total layers: 154, Fine-tuning last 30 layers
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 224, 224, 3  0           []
                                )]

 Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']
                                )

 bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']
                                )

 Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']
                                )

 expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']
 wiseConv2D)                    )

 expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']
 tchNormalization)              )

 expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0
 ReLU)                          )                                ]']

 expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]
                                )                                [0]']

 expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']
 hNormalization)                )

 block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'
                                )                                ]

 block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']
 ization)                       )

 block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']
                                )

 block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']
                                )

 block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']
 nv2D)

 block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']
 malization)

 block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']

 block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]']

 block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']
 lization)

 block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']

 block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']
 ization)

 block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']

 block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']
 nv2D)

 block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']
 malization)

 block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']

 block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]']

 block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']
 lization)

 block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',
                                                                  'block_2_project_BN[0][0]']

 block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']

 block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']
 ization)

 block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']

 block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']

 block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']
 nv2D)

 block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']
 malization)

 block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']

 block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]']

 block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']
 lization)

 block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']

 block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']
 ization)

 block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']

 block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']
 nv2D)

 block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']
 malization)

 block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']

 block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]']

 block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']
 lization)

 block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',
                                                                  'block_4_project_BN[0][0]']

 block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']

 block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']
 ization)

 block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']

 block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']
 nv2D)

 block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']
 malization)

 block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']

 block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]']

 block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']
 lization)

 block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',
                                                                  'block_5_project_BN[0][0]']

 block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']

 block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']
 ization)

 block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']

 block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']

 block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']
 nv2D)

 block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']
 malization)

 block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']

 block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]']

 block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']
 lization)

 block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']

 block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']
 ization)

 block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']

 block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']
 nv2D)

 block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']
 malization)

 block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']

 block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]']

 block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']
 lization)

 block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',
                                                                  'block_7_project_BN[0][0]']

 block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']

 block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']
 ization)

 block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']

 block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']
 nv2D)

 block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']
 malization)

 block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']

 block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]']

 block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']
 lization)

 block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',
                                                                  'block_8_project_BN[0][0]']

 block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']

 block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']
 ization)

 block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']

 block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']
 nv2D)

 block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']
 malization)

 block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']

 block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]']

 block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']
 lization)

 block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',
                                                                  'block_9_project_BN[0][0]']

 block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']

 block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']
 lization)

 block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']

 block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']
 onv2D)

 block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']
 rmalization)

 block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']

 block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']

 block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']
 alization)

 block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']

 block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']
 lization)

 block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']

 block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']
 onv2D)

 block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']
 rmalization)

 block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']

 block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']

 block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']
 alization)

 block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',
                                                                  'block_11_project_BN[0][0]']

 block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']

 block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']
 lization)

 block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']

 block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']
 onv2D)

 block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']
 rmalization)

 block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']

 block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']

 block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']
 alization)

 block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',
                                                                  'block_12_project_BN[0][0]']

 block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']

 block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']
 lization)

 block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']

 block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']

 block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']
 onv2D)

 block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']
 rmalization)

 block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']

 block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']

 block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']
 alization)

 block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']

 block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']
 lization)

 block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']

 block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']
 onv2D)

 block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']
 rmalization)

 block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']

 block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']

 block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']
 alization)

 block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',
                                                                  'block_14_project_BN[0][0]']

 block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']

 block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']
 lization)

 block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']

 block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']
 onv2D)

 block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']
 rmalization)

 block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']

 block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']

 block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']
 alization)

 block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',
                                                                  'block_15_project_BN[0][0]']

 block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']

 block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']
 lization)

 block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']

 block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']
 onv2D)

 block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']
 rmalization)

 block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']

 block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']

 block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']
 alization)

 Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']

 Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']

 out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']

 conv2d (Conv2D)                (None, 7, 7, 128)    1474688     ['out_relu[0][0]']

 max_pooling2d (MaxPooling2D)   (None, 3, 3, 128)    0           ['conv2d[0][0]']

 batch_normalization (BatchNorm  (None, 3, 3, 128)   512         ['max_pooling2d[0][0]']
 alization)

 conv2d_1 (Conv2D)              (None, 3, 3, 128)    147584      ['batch_normalization[0][0]']

 max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 128)   0           ['conv2d_1[0][0]']

 batch_normalization_1 (BatchNo  (None, 1, 1, 128)   512         ['max_pooling2d_1[0][0]']
 rmalization)

 flatten (Flatten)              (None, 128)          0           ['batch_normalization_1[0][0]']

 dense (Dense)                  (None, 512)          66048       ['flatten[0][0]']

 batch_normalization_2 (BatchNo  (None, 512)         2048        ['dense[0][0]']
 rmalization)

 dropout (Dropout)              (None, 512)          0           ['batch_normalization_2[0][0]']

 dense_1 (Dense)                (None, 256)          131328      ['dropout[0][0]']

 batch_normalization_3 (BatchNo  (None, 256)         1024        ['dense_1[0][0]']
 rmalization)

 dropout_1 (Dropout)            (None, 256)          0           ['batch_normalization_3[0][0]']

 dense_2 (Dense)                (None, 128)          32896       ['dropout_1[0][0]']

 batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_2[0][0]']
 rmalization)

 dropout_2 (Dropout)            (None, 128)          0           ['batch_normalization_4[0][0]']

 dense_3 (Dense)                (None, 9)            1161        ['dropout_2[0][0]']

==================================================================================================
Total params: 4,116,297
Trainable params: 4,079,881
Non-trainable params: 36,416
__________________________________________________________________________________________________
Epoch 1/100
2025-04-04 13:42:04.819052: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8907
2025-04-04 13:42:06.251808: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
 57/369 [===>..........................] - ETA: 1:12 - loss: 3.0531 - accuracy: 0.3136C:\Program Files\Python310\lib\site-packages\PIL\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
369/369 [==============================] - ETA: 0s - loss: 2.0012 - accuracy: 0.6189
Epoch 1: val_loss improved from inf to 3.60600, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 128s 326ms/step - loss: 2.0012 - accuracy: 0.6189 - val_loss: 3.6060 - val_accuracy: 0.4253 - lr: 0.0010
Epoch 2/100
369/369 [==============================] - ETA: 0s - loss: 1.3790 - accuracy: 0.7911
Epoch 2: val_loss improved from 3.60600 to 2.49933, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 108s 292ms/step - loss: 1.3790 - accuracy: 0.7911 - val_loss: 2.4993 - val_accuracy: 0.5299 - lr: 0.0010
Epoch 3/100
369/369 [==============================] - ETA: 0s - loss: 1.1895 - accuracy: 0.8199
Epoch 3: val_loss did not improve from 2.49933
369/369 [==============================] - 107s 288ms/step - loss: 1.1895 - accuracy: 0.8199 - val_loss: 2.7021 - val_accuracy: 0.4677 - lr: 0.0010
Epoch 4/100
369/369 [==============================] - ETA: 0s - loss: 1.0558 - accuracy: 0.8357
Epoch 4: val_loss did not improve from 2.49933
369/369 [==============================] - 110s 296ms/step - loss: 1.0558 - accuracy: 0.8357 - val_loss: 2.5396 - val_accuracy: 0.5469 - lr: 0.0010
Epoch 5/100
369/369 [==============================] - ETA: 0s - loss: 0.9156 - accuracy: 0.8528
Epoch 5: val_loss improved from 2.49933 to 1.80796, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 139s 377ms/step - loss: 0.9156 - accuracy: 0.8528 - val_loss: 1.8080 - val_accuracy: 0.6505 - lr: 0.0010
Epoch 6/100
369/369 [==============================] - ETA: 0s - loss: 0.8589 - accuracy: 0.8479
Epoch 6: val_loss improved from 1.80796 to 1.79993, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 141s 381ms/step - loss: 0.8589 - accuracy: 0.8479 - val_loss: 1.7999 - val_accuracy: 0.6325 - lr: 0.0010
Epoch 7/100
369/369 [==============================] - ETA: 0s - loss: 0.7474 - accuracy: 0.8602
Epoch 7: val_loss did not improve from 1.79993
369/369 [==============================] - 127s 342ms/step - loss: 0.7474 - accuracy: 0.8602 - val_loss: 2.3587 - val_accuracy: 0.5126 - lr: 0.0010
Epoch 8/100
369/369 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.8636
Epoch 8: val_loss improved from 1.79993 to 1.76592, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 128s 346ms/step - loss: 0.6789 - accuracy: 0.8636 - val_loss: 1.7659 - val_accuracy: 0.5938 - lr: 0.0010
Epoch 9/100
369/369 [==============================] - ETA: 0s - loss: 0.6574 - accuracy: 0.8664
Epoch 9: val_loss did not improve from 1.76592
369/369 [==============================] - 126s 340ms/step - loss: 0.6574 - accuracy: 0.8664 - val_loss: 2.3044 - val_accuracy: 0.5221 - lr: 0.0010
Epoch 10/100
369/369 [==============================] - ETA: 0s - loss: 0.6121 - accuracy: 0.8690
Epoch 10: val_loss did not improve from 1.76592
369/369 [==============================] - 127s 342ms/step - loss: 0.6121 - accuracy: 0.8690 - val_loss: 2.6336 - val_accuracy: 0.4688 - lr: 0.0010
Epoch 11/100
369/369 [==============================] - ETA: 0s - loss: 0.5933 - accuracy: 0.8721
Epoch 11: val_loss improved from 1.76592 to 1.59343, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 126s 340ms/step - loss: 0.5933 - accuracy: 0.8721 - val_loss: 1.5934 - val_accuracy: 0.6675 - lr: 0.0010
Epoch 12/100
369/369 [==============================] - ETA: 0s - loss: 0.5597 - accuracy: 0.8765
Epoch 12: val_loss did not improve from 1.59343
369/369 [==============================] - 127s 342ms/step - loss: 0.5597 - accuracy: 0.8765 - val_loss: 1.9317 - val_accuracy: 0.6087 - lr: 0.0010
Epoch 13/100
369/369 [==============================] - ETA: 0s - loss: 0.5564 - accuracy: 0.8784
Epoch 13: val_loss improved from 1.59343 to 1.17716, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 127s 344ms/step - loss: 0.5564 - accuracy: 0.8784 - val_loss: 1.1772 - val_accuracy: 0.7276 - lr: 0.0010
Epoch 14/100
369/369 [==============================] - ETA: 0s - loss: 0.5384 - accuracy: 0.8775
Epoch 14: val_loss did not improve from 1.17716
369/369 [==============================] - 125s 339ms/step - loss: 0.5384 - accuracy: 0.8775 - val_loss: 1.3576 - val_accuracy: 0.6810 - lr: 0.0010
Epoch 15/100
369/369 [==============================] - ETA: 0s - loss: 0.5212 - accuracy: 0.8856
Epoch 15: val_loss did not improve from 1.17716
369/369 [==============================] - 126s 341ms/step - loss: 0.5212 - accuracy: 0.8856 - val_loss: 1.4284 - val_accuracy: 0.6478 - lr: 0.0010
Epoch 16/100
369/369 [==============================] - ETA: 0s - loss: 0.5299 - accuracy: 0.8823
Epoch 16: val_loss did not improve from 1.17716

Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
369/369 [==============================] - 126s 340ms/step - loss: 0.5299 - accuracy: 0.8823 - val_loss: 1.7677 - val_accuracy: 0.5948 - lr: 0.0010
Epoch 17/100
369/369 [==============================] - ETA: 0s - loss: 0.3688 - accuracy: 0.9247
Epoch 17: val_loss improved from 1.17716 to 0.89275, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 125s 339ms/step - loss: 0.3688 - accuracy: 0.9247 - val_loss: 0.8928 - val_accuracy: 0.7921 - lr: 1.0000e-04
Epoch 18/100
369/369 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.9390
Epoch 18: val_loss improved from 0.89275 to 0.60755, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 126s 340ms/step - loss: 0.3043 - accuracy: 0.9390 - val_loss: 0.6076 - val_accuracy: 0.8492 - lr: 1.0000e-04
Epoch 19/100
369/369 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.9501
Epoch 19: val_loss improved from 0.60755 to 0.45981, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 126s 342ms/step - loss: 0.2644 - accuracy: 0.9501 - val_loss: 0.4598 - val_accuracy: 0.8896 - lr: 1.0000e-04
Epoch 20/100
369/369 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9573
Epoch 20: val_loss improved from 0.45981 to 0.39942, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 127s 343ms/step - loss: 0.2332 - accuracy: 0.9573 - val_loss: 0.3994 - val_accuracy: 0.9015 - lr: 1.0000e-04
Epoch 21/100
369/369 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9573
Epoch 21: val_loss improved from 0.39942 to 0.29433, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 127s 343ms/step - loss: 0.2214 - accuracy: 0.9573 - val_loss: 0.2943 - val_accuracy: 0.9273 - lr: 1.0000e-04
Epoch 22/100
369/369 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9625
Epoch 22: val_loss improved from 0.29433 to 0.29186, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 126s 341ms/step - loss: 0.2014 - accuracy: 0.9625 - val_loss: 0.2919 - val_accuracy: 0.9317 - lr: 1.0000e-04
Epoch 23/100
369/369 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9653
Epoch 23: val_loss did not improve from 0.29186
369/369 [==============================] - 125s 338ms/step - loss: 0.1772 - accuracy: 0.9653 - val_loss: 0.3036 - val_accuracy: 0.9314 - lr: 1.0000e-04
Epoch 24/100
369/369 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.9672
Epoch 24: val_loss did not improve from 0.29186
369/369 [==============================] - 126s 340ms/step - loss: 0.1752 - accuracy: 0.9672 - val_loss: 0.3230 - val_accuracy: 0.9283 - lr: 1.0000e-04
Epoch 25/100
369/369 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.9681
Epoch 25: val_loss did not improve from 0.29186

Epoch 25: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
369/369 [==============================] - 126s 340ms/step - loss: 0.1651 - accuracy: 0.9681 - val_loss: 0.2935 - val_accuracy: 0.9283 - lr: 1.0000e-04
Epoch 26/100
369/369 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 0.9729
Epoch 26: val_loss improved from 0.29186 to 0.26996, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 126s 341ms/step - loss: 0.1461 - accuracy: 0.9729 - val_loss: 0.2700 - val_accuracy: 0.9378 - lr: 1.0000e-05
Epoch 27/100
369/369 [==============================] - ETA: 0s - loss: 0.1398 - accuracy: 0.9764
Epoch 27: val_loss improved from 0.26996 to 0.26968, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 127s 342ms/step - loss: 0.1398 - accuracy: 0.9764 - val_loss: 0.2697 - val_accuracy: 0.9416 - lr: 1.0000e-05
Epoch 28/100
369/369 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9780
Epoch 28: val_loss did not improve from 0.26968
369/369 [==============================] - 125s 337ms/step - loss: 0.1333 - accuracy: 0.9780 - val_loss: 0.2822 - val_accuracy: 0.9372 - lr: 1.0000e-05
Epoch 29/100
369/369 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.9770
Epoch 29: val_loss improved from 0.26968 to 0.26816, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 127s 343ms/step - loss: 0.1299 - accuracy: 0.9770 - val_loss: 0.2682 - val_accuracy: 0.9409 - lr: 1.0000e-05
Epoch 30/100
369/369 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9758
Epoch 30: val_loss did not improve from 0.26816
369/369 [==============================] - 126s 341ms/step - loss: 0.1341 - accuracy: 0.9758 - val_loss: 0.2701 - val_accuracy: 0.9416 - lr: 1.0000e-05
Epoch 31/100
369/369 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9779
Epoch 31: val_loss improved from 0.26816 to 0.26665, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 127s 342ms/step - loss: 0.1216 - accuracy: 0.9779 - val_loss: 0.2667 - val_accuracy: 0.9361 - lr: 1.0000e-05
Epoch 32/100
369/369 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9796
Epoch 32: val_loss did not improve from 0.26665
369/369 [==============================] - 125s 337ms/step - loss: 0.1200 - accuracy: 0.9796 - val_loss: 0.2698 - val_accuracy: 0.9385 - lr: 1.0000e-05
Epoch 33/100
369/369 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 0.9795
Epoch 33: val_loss improved from 0.26665 to 0.25416, saving model to mobilenet_saved_2025-04-04_13-41-54.keras
369/369 [==============================] - 126s 341ms/step - loss: 0.1254 - accuracy: 0.9795 - val_loss: 0.2542 - val_accuracy: 0.9470 - lr: 1.0000e-05
Epoch 34/100
369/369 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.9782
Epoch 34: val_loss did not improve from 0.25416
369/369 [==============================] - 126s 340ms/step - loss: 0.1272 - accuracy: 0.9782 - val_loss: 0.2685 - val_accuracy: 0.9453 - lr: 1.0000e-05
Epoch 35/100
369/369 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9794
Epoch 35: val_loss did not improve from 0.25416
369/369 [==============================] - 126s 339ms/step - loss: 0.1218 - accuracy: 0.9794 - val_loss: 0.2603 - val_accuracy: 0.9412 - lr: 1.0000e-05
Epoch 36/100
369/369 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9799
Epoch 36: val_loss did not improve from 0.25416

Epoch 36: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
369/369 [==============================] - 126s 339ms/step - loss: 0.1184 - accuracy: 0.9799 - val_loss: 0.2671 - val_accuracy: 0.9409 - lr: 1.0000e-05
Epoch 37/100
369/369 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.9835
Epoch 37: val_loss did not improve from 0.25416
369/369 [==============================] - 126s 341ms/step - loss: 0.1104 - accuracy: 0.9835 - val_loss: 0.2679 - val_accuracy: 0.9412 - lr: 1.0000e-06
Epoch 38/100
369/369 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9797
Epoch 38: val_loss did not improve from 0.25416
369/369 [==============================] - 126s 342ms/step - loss: 0.1187 - accuracy: 0.9797 - val_loss: 0.2685 - val_accuracy: 0.9416 - lr: 1.0000e-06
Epoch 39/100
369/369 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9784
Epoch 39: val_loss did not improve from 0.25416

Epoch 39: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.
369/369 [==============================] - 126s 341ms/step - loss: 0.1214 - accuracy: 0.9784 - val_loss: 0.2706 - val_accuracy: 0.9375 - lr: 1.0000e-06
Epoch 40/100
369/369 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9800
Epoch 40: val_loss did not improve from 0.25416
369/369 [==============================] - 126s 340ms/step - loss: 0.1129 - accuracy: 0.9800 - val_loss: 0.2886 - val_accuracy: 0.9338 - lr: 1.0000e-07
Epoch 41/100
369/369 [==============================] - ETA: 0s - loss: 0.1171 - accuracy: 0.9804
Epoch 41: val_loss did not improve from 0.25416
369/369 [==============================] - 126s 341ms/step - loss: 0.1171 - accuracy: 0.9804 - val_loss: 0.2615 - val_accuracy: 0.9433 - lr: 1.0000e-07
Epoch 42/100
369/369 [==============================] - ETA: 0s - loss: 0.1144 - accuracy: 0.9800
Epoch 42: val_loss did not improve from 0.25416

Epoch 42: ReduceLROnPlateau reducing learning rate to 1e-07.
369/369 [==============================] - 124s 336ms/step - loss: 0.1144 - accuracy: 0.9800 - val_loss: 0.2549 - val_accuracy: 0.9446 - lr: 1.0000e-07
Epoch 43/100
369/369 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9807
Epoch 43: val_loss did not improve from 0.25416
369/369 [==============================] - 126s 341ms/step - loss: 0.1196 - accuracy: 0.9807 - val_loss: 0.2660 - val_accuracy: 0.9443 - lr: 1.0000e-07
Test Accuracy: 0.9579
115/115 [==============================] - 8s 66ms/step
Classification Report:
              precision    recall  f1-score   support

     battery       0.96      0.98      0.97       260
   cardboard       0.98      0.91      0.94       278
     clothes       0.99      0.99      0.99      1006
       glass       0.95      0.91      0.93       401
       metal       0.90      0.92      0.91       272
     organic       0.98      0.95      0.97       363
       paper       0.92      0.96      0.94       309
     plastic       0.91      0.94      0.93       396
       shoes       0.96      0.98      0.97       395

    accuracy                           0.96      3680
   macro avg       0.95      0.95      0.95      3680
weighted avg       0.96      0.96      0.96      3680

Confusion Matrix: [[254   1   0   1   1   0   0   2   1]
 [  2 253   3   0   2   0  16   2   0]
 [  0   0 998   0   1   0   4   2   1]
 [  0   1   1 365  12   2   0  18   2]
 [  6   0   0   6 251   0   1   4   4]
 [  0   1   0   5   2 346   0   3   6]
 [  0   2   0   1   2   1 298   3   2]
 [  2   0   0   7   6   1   4 374   2]
 [  1   0   2   0   1   3   1   1 386]]

Process finished with exit code 0

